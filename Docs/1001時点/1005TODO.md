P0 強化パッチ（貼るだけ／例外内容を確実に出す）

以下を rag_core/core.py（あるいはベクトルストアを扱う層）と API ハンドラに差し込み。

例外は logger.exception でトレース出力

/search は detail に例外文字列を返す（暫定。後で 4xx/5xx で出し分け）

--- a/rag_core/core.py
+++ b/rag_core/core.py
@@
+import logging, os
+from pathlib import Path
+log = logging.getLogger(__name__)
+
+S3_BUCKET = os.getenv("S3_BUCKET_NAME") or os.getenv("RAG_S3_BUCKET")
+S3_PREFIX = os.getenv("S3_PREFIX") or os.getenv("RAG_S3_PREFIX")
+_MODEL_RAW = os.getenv("BEDROCK_EMBEDDINGS_MODEL_ID") or os.getenv("RAG_EMBEDDING") or "amazon.titan-embed-text-v2"
+# Titanの表記ゆれ吸収（末尾 :0 を許容）
+BEDROCK_MODEL_ID = _MODEL_RAW.replace(":0", "")
+
 def _download_vectorstore_from_s3(local_dir: Path) -> bool:
-    ...
+    log.info("S3 download start: bucket=%s prefix=%s local=%s", S3_BUCKET, S3_PREFIX, local_dir)
+    try:
+        local_dir.mkdir(parents=True, exist_ok=True)
+        # index.faiss / index.pkl を明示
+        for key in ("index.faiss","index.pkl"):
+            s3_key = f"{S3_PREFIX.rstrip('/')}/{key}"
+            dst = local_dir / key
+            _s3_download(S3_BUCKET, s3_key, dst)  # 既存のダウンロード関数を呼ぶ
+            log.info("S3 downloaded: s3://%s/%s -> %s (exists=%s size=%s)",
+                     S3_BUCKET, s3_key, dst, dst.exists(), dst.stat().st_size if dst.exists() else -1)
+        return True
+    except Exception:
+        log.exception("S3 download failed")
+        return False
@@
 def build_or_load_vectorstore(docs: Optional[List[Document]] = None) -> FAISS:
-    ...
+    try:
+        local = Path("/tmp/vectorstore")
+        has_remote = _download_vectorstore_from_s3(local)
+        embeddings = BedrockEmbeddings(model_id=BEDROCK_MODEL_ID)  # 実装に合わせる
+        if has_remote:
+            vs = FAISS.load_local(local, embeddings, allow_dangerous_deserialization=True)
+            log.info("FAISS loaded from %s (model=%s)", local, BEDROCK_MODEL_ID)
+            return vs
+        # Fallback: docs から再構築（本番では原則使わない想定）
+        if docs:
+            vs = FAISS.from_documents(docs, embeddings)
+            log.info("FAISS built from docs (model=%s)", BEDROCK_MODEL_ID)
+            return vs
+        raise RuntimeError("No vectorstore available (S3 download failed and no docs)")
+    except Exception:
+        log.exception("FAISS init failed")
+        raise
@@
 def search_vendors(vs: FAISS, query: str, k: int = 5):
-    ...
+    try:
+        results = vs.similarity_search_with_score(query, k=k)
+        log.info("search ok: query=%r hits=%d", query, len(results))
+        return results
+    except Exception:
+        log.exception("search failed: query=%r", query)
+        raise

--- a/api/routes.py
+++ b/api/routes.py
@@
-from fastapi import APIRouter
-from fastapi.responses import JSONResponse
+from fastapi import APIRouter
+from fastapi.responses import JSONResponse
+import logging
+log = logging.getLogger(__name__)
 
 @router.post("/search")
 async def search(payload: SearchRequest):
-    results = do_search(payload.query, k=payload.k or 5)
-    return {"results": normalize(results)}
+    try:
+        results = do_search(payload.query, k=payload.k or 5)
+        return {"results": normalize(results)}
+    except Exception as e:
+        log.exception("search endpoint failed")
+        # 一旦メッセージを detail に返す（暫定）
+        return JSONResponse(status_code=500, content={"detail": str(e)})


FastAPI/Uvicorn のルートで 構成ログも一度だけ出すと特定が速いです（起動直後に一回だけ）。

log.info("CONFIG: bucket=%s prefix=%s model=%s region=%s",
         S3_BUCKET, S3_PREFIX, BEDROCK_MODEL_ID, os.getenv("AWS_REGION"))


CORS（ブラウザNG・curl OK 対策）
バックエンドにこれがなければ追記（Amplify/本番ドメインを列挙）。

from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(
    CORSMiddleware,
-   allow_origins=["*"],  # 一時的に全許可でも可（切り戻し忘れに注意）
+   allow_origins=["https://<amplify-domain>.amplifyapp.com", "https://<prod-frontend-domain>"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

P1 環境変数を一本化（ECS）

提示の手順でOK。まずは BEDROCK_EMBEDDINGS_MODEL_ID=amazon.titan-embed-text-v2（末尾なし）に固定。
コード側で :0 を除去しているので、ECS が旧値でも落ちませんが、見た目も合わせるのが吉。

余力あれば：起動時に モデル疎通チェックを追加（1トークン埋め込み試打）。

try:
    _ = BedrockEmbeddings(model_id=BEDROCK_MODEL_ID).embed_query("ping")
    log.info("Bedrock embeddings warmup ok")
except Exception:
    log.exception("Bedrock embeddings warmup failed")
    raise

P2 可視化ワンライナー（ログ定型）

（すでに近いものを書かれているので、search 実行直後の 90 秒ウィンドウで拾う版）

LOG_GROUP=/ecs/vendor0919-api
LOG_STREAM=$(aws logs describe-log-streams --log-group-name $LOG_GROUP \
  --order-by LastEventTime --descending --limit 1 \
  --query "logStreams[0].logStreamName" --output text)

# 直近90秒でFAISS/Exception/bedrockのワードを抽出
aws logs filter-log-events \
  --log-group-name $LOG_GROUP --log-stream-names "$LOG_STREAM" \
  --start-time $(($(date +%s) * 1000 - 90000)) \
  --end-time   $(($(date +%s) * 1000)) \
  --filter-pattern "FAISS|Exception|Error|bedrock|download|search" \
  --limit 200 --query "events[*].message" --output text

P3 “よく落ちる根っこ” 早見表（明日の切り分け順）

FAISS ファイル欠落／サイズ 0
　→ P0 ログで size=-1 or 0 が出る。S3 パス/権限/暗号化を確認（s3:GetObject）。

埋め込みモデル不整合（v1 vs v2）
　→ 起動ログに Bedrock embeddings warmup failed。インデックス生成と同じモデルで再生成。

IAM 権限不足（bedrock:InvokeModel / logs:PutLogEvents）
　→ AccessDeniedException／UnrecognizedClientException。タスクロールを確認。

プロセス未捕捉例外で再起動
　→ Shutting down 直前に Exception のトレースが出る（P0で可視化）。

CORS/ALB ヘルス差異
　→ curl OK / ブラウザ NG はほぼ CORS。Access-Control-Allow-Origin を確認。

起動時プリウォーム（任意）

初回検索で落ちるのを避けるため、起動完了時に S3→FAISS ロード＋embed pingを行い、
/health で ready: true を返すように。

--- a/api/health.py
@@
-ready = True
+ready = False
+try:
+    _ = build_or_load_vectorstore()
+    ready = True
+except Exception:
+    logging.getLogger(__name__).exception("warmup failed")
 
 @router.get("/health")
 def health():
     return {"status": "ok", "ready": ready}


ECS の HealthCheckGracePeriodSeconds=60–120 にしておくと、初回ロード時間を吸収できます。

30分スプリント手順（明朝）

強化パッチを入れて再デプロイ（環境変数も統一）。

curl -s -X POST /search → 直後 90秒ログで FAISS loaded / 例外を確認。

例外が S3/FAISS 起因なら：S3 実体・サイズ・権限を修正。
Bedrock 起因なら：モデル ID / IAM / VPC エンドポイント可否を修正。

再テスト → フロントで CORS/表示確認。

追加：Cursor 用「差分パッチ依頼プロンプト」

これを Cursor に渡すと、上記パッチを “最小変更” で入れてくれます。

プロジェクト全体に以下を反映してください（最小差分で）：
1) 例外ハンドリング強化：FAISS 初期化・検索・S3ダウンロードの try/except に logger.exception を追加。ログ文言は本スレのP0パッチに準拠。
2) 起動時構成ログ（bucket/prefix/model/region）を1回だけ出力。
3) BedrockモデルIDの表記ゆれ吸収：環境変数 BEDROCK_EMBEDDINGS_MODEL_ID (推奨) と RAG_EMBEDDING (互換) を読み、末尾 :0 は除去。
4) /search ハンドラで例外内容を 500 の JSON detail に一旦通す（暫定運用）。logger.exception も必ず呼ぶ。
5) CORS ミドルウェアで Amplify/本番ドメインを allow_origins に設定（既存が * の場合は TODO コメントを残し将来閉じる）。
6) 起動プリウォーム（任意フラグ可）：S3→FAISS ロードと Bedrock embed_query("ping") を試し、失敗時は起動エラーにする。/health に ready フラグを反映。


必要なら、FAISS の“再生成ワンショット”スクリプト（vendors.json→index.faiss/index.pkl→S3 put）も書きます。まずはこのパッチ＋ログで、どこで落ちているかを明確化しましょう。

あなた:
こういうコメントもあったので記憶よろしく
気になる点

Bedrock モデル ID

以前エラーが ValidationException: The provided model identifier is invalid. でした。

Bedrock の埋め込みモデルは現在 "amazon.titan-embed-text-v2" までで、:0 のようなバージョン付きの形式は無効かもしれません。

つまり amazon.titan-embed-text-v2:0 → amazon.titan-embed-text-v2 に直す必要がありそう。

環境変数の重複

S3_BUCKET_NAME と RAG_S3_BUCKET が両方あり、S3_PREFIX と RAG_S3_PREFIX も両方あり。

コードによっては S3_BUCKET_NAME を見に行き、別の箇所は RAG_S3_BUCKET を見に行っているかも。

これは統一するか、コード側でどちらを参照しているか確認した方がよいです。
ChatGPT:
保存されたメモリを更新しました
思考時間: 4 秒

了解、記憶しました！

Bedrock埋め込みモデルIDは amazon.titan-embed-text-v2（末尾 :0 なし） を基本に。:0 を付けると ValidationException になる可能性あり。

環境変数は S3_BUCKET_NAME / S3_PREFIX に統一。コード側で旧 RAG_S3_BUCKET / RAG_S3_PREFIX を参照していないか監査する。