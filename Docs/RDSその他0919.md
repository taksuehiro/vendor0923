全体サマリ（結論だけ先に）

ALB + ECS(Fargate) は稼働。ALB /health は 200、ターゲットは healthy、ログは S3 連携済み。

RDS(Postgres 単体) は VPC/サブネット/SGの食い違いで遠回り → 取り下げ。

Aurora Serverless v2 (PostgreSQL) を private で構築完了（vendor0913 と同じ方針）。
外部（CloudShell/ローカル）からは 繋がらないのが正しい。ECS から繋げばOK。

なので次にやることは ECS タスク内から DB 接続確認 → アプリに環境変数を流し込んで ALB 経由でアプリ動作確認。
ついでに開けすぎた SG を閉じておく。

ここまでの主要リソース & 事実

VPC（アプリ系）: vpc-0484f20452b5a7773

Public Subnets:

subnet-0d9d1c034ff3310ca (1a)

subnet-0fad2d28b04a7e2b5 (1c)

ALB SG: sg-0fa3ee4b2af769436（ALB for vendor0919）

ECS Service SG: sg-023a5d27e13e2a967（ECSサービス側、:8080 を ALB SG から許可）

RDS/Aurora SG: sg-052aaf25ecb8c2e86（現状 5432 を ECS SG から許可。途中で 0.0.0.0/0 を追加もした）

ALB アクセスログ: バケット vendor0919-alb-logs に出力（バケットポリシー適用済み）

ECS 健康: ターゲット healthy、/health が 200

Aurora Serverless v2:

Cluster: vendor0919-aurora-cluster（engine: aurora-postgresql 15.5、Serverless v2 設定済）

Instance: vendor0919-aurora-instance-1（db.serverless, private）

外部直アクセスは不可（仕様通り）。ECS から疎通すべし

ミス/詰まりポイント（教訓）

VPC不一致のSGをRDSに指定 → InvalidParameterCombination
↳ DB と SG は 同一VPC で。

private subnet で RDSを public にしようとして失敗
↳ public が必要なら public subnet グループ + IGW ルート + VPC DNS 有効 が前提。

PubliclyAccessible は作成後に切り替え不可
↳ 変えたくなったら 削除→再作成 一択。

Aurora Serverless v2 はクラスタに v2 スケーリング設定が先
↳ modify-db-cluster --serverless-v2-scaling-configuration ... → その後に create-db-instance.

使った/使える確認コマンド集（再掲・整理）
ネットワーク/SG/サブネット
# サブネット一覧（どれが public か）
aws ec2 describe-subnets \
  --region ap-northeast-1 \
  --query "Subnets[*].{id:SubnetId,az:AvailabilityZone,mapPubIp:MapPublicIpOnLaunch,vpc:VpcId}" \
  --output table

# SG ルール確認
aws ec2 describe-security-groups \
  --group-ids sg-052aaf25ecb8c2e86 \
  --region ap-northeast-1 \
  --query "SecurityGroups[0].IpPermissions"

ECS/ALB 健康
# ターゲットヘルス
aws elbv2 describe-target-health \
  --target-group-arn <TG-ARN> \
  --region ap-northeast-1

# アプリヘルス
curl http://<ALB-DNS>/health

Aurora
# クラスタのエンドポイントなど
aws rds describe-db-clusters \
  --db-cluster-identifier vendor0919-aurora-cluster \
  --region ap-northeast-1 \
  --query "DBClusters[0].{status:Status,writer:Endpoint,reader:ReaderEndpoint}"

# インスタンスの状態と個別エンドポイント
aws rds describe-db-instances \
  --db-instance-identifier vendor0919-aurora-instance-1 \
  --region ap-northeast-1 \
  --query "DBInstances[0].{status:DBInstanceStatus,endpoint:Endpoint.Address,public:PubliclyAccessible}"





1) ECS Exec 準備まわり（最初にハマったところ）
症状

aws ecs execute-command が InvalidParameterException で失敗

execute command was not enabled when the task was run or the execute command agent isn’t running

さらにサービス更新時に

The service couldn't be updated because a valid taskRoleArn is not being used.

対応

クラスター側で Exec を有効化

aws ecs update-cluster \
  --cluster vendor0919-cluster \
  --configuration "executeCommandConfiguration={logging=DEFAULT}" \
  --region ap-northeast-1


サービス側でも Exec 有効化（※有効化後に起動したタスクでしか使えない）

aws ecs update-service \
  --cluster vendor0919-cluster \
  --service vendor0919-service \
  --enable-execute-command \
  --region ap-northeast-1


taskRole が存在しなかったので新規作成（信頼ポリシー：ecs-tasks.amazonaws.com）

aws iam create-role \
  --role-name ecsTaskRole-vendor0919 \
  --assume-role-policy-document '{
    "Version":"2012-10-17",
    "Statement":[{"Effect":"Allow","Principal":{"Service":"ecs-tasks.amazonaws.com"},"Action":"sts:AssumeRole"}]
  }'


Exec 用に タスクロールへ SSM ポリシー付与

aws iam attach-role-policy \
  --role-name ecsTaskRole-vendor0919 \
  --policy-arn arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore


既存タスクは Exec 無効なままなので 停止→新タスク起動

aws ecs stop-task --cluster vendor0919-cluster --task <古いタスクID> --region ap-northeast-1
aws ecs update-service --cluster vendor0919-cluster --service vendor0919-service --force-new-deployment --region ap-northeast-1

追加（VPC エンドポイント）

NATなし構成で SSM/Exec を通すため、Interface VPC Endpoint を3つ作成（VPC: vpc-0484f20452b5a7773 / Subnet: subnet-0d9d1c034ff3310ca / SG: sg-023a5d27e13e2a967）

com.amazonaws.ap-northeast-1.ssm

com.amazonaws.ap-northeast-1.ssmmessages

com.amazonaws.ap-northeast-1.ec2messages

aws ec2 create-vpc-endpoint \
  --vpc-id vpc-0484f20452b5a7773 \
  --vpc-endpoint-type Interface \
  --service-name com.amazonaws.ap-northeast-1.{ssm,ssmmessages,ec2messages} \
  --subnet-ids subnet-0d9d1c034ff3310ca \
  --security-group-ids sg-023a5d27e13e2a967 \
  --region ap-northeast-1

2) CloudWatch Logs がなくてタスク即死
症状

タスクが DEPROVISIONING 直後停止

stoppedReason:

ResourceInitializationError: failed to create Cloudwatch log stream: 
ResourceNotFoundException: The specified log group does not exist.

対応

タスク定義のログ設定は awslogs-group: /ecs/vendor0919 になってた

ロググループを先に作成

aws logs create-log-group --log-group-name /ecs/vendor0919 --region ap-northeast-1


サービス再デプロイ

aws ecs update-service \
  --cluster vendor0919-cluster \
  --service vendor0919-service \
  --force-new-deployment \
  --region ap-northeast-1

3) コンテナ内で psycopg2 が無くてクラッシュ
症状（CloudWatch Logs）
ModuleNotFoundError: No module named 'psycopg2'

対応

backend/requirements.txt に追記

psycopg2-binary==2.9.9


イメージ再ビルド＆ECRへ push（リポジトリ：067717894185.dkr.ecr.ap-northeast-1.amazonaws.com/vendor0919-api:latest）

# ログイン
aws ecr get-login-password --region ap-northeast-1 | \
  docker login --username AWS --password-stdin 067717894185.dkr.ecr.ap-northeast-1.amazonaws.com

# ビルド & プッシュ
cd backend
docker build -t vendor0919-api:latest .
docker tag vendor0919-api:latest 067717894185.dkr.ecr.ap-northeast-1.amazonaws.com/vendor0919-api:latest
docker push 067717894185.dkr.ecr.ap-northeast-1.amazonaws.com/vendor0919-api:latest
# 例: pushed digest sha256:1cf036b50eb38f3b...


サービス再デプロイ

aws ecs update-service \
  --cluster vendor0919-cluster \
  --service vendor0919-service \
  --force-new-deployment \
  --region ap-northeast-1

4) ALB ヘルスチェック調整
変更点

ターゲットグループ vendor0919-tg/09902b0116e2f1dd の ヘルスチェックパスを /health に変更

aws elbv2 modify-target-group \
  --target-group-arn arn:aws:elasticloadbalancing:ap-northeast-1:067717894185:targetgroup/vendor0919-tg/09902b0116e2f1dd \
  --health-check-path /health \
  --region ap-northeast-1


FastAPI に /health 実装済み（200 OK 確認）

5) 環境変数が空で DB 接続がローカルソケットになってた
症状（/db-check 初回）
connection to server on socket "/var/run/postgresql/.s.PGSQL.5432" failed


→ ECS タスク定義の environment が空で、DB_HOST 等が渡ってなかった

対応（タスク定義の修正）

現行タスク定義（vendor0919-task:3）を td.json に保存して編集

containerDefinitions[0].environment を以下で上書き：

"environment": [
  { "name": "DB_HOST", "value": "vendor0919-aurora-instance-1.czicicu6kcc8.ap-northeast-1.rds.amazonaws.com" },
  { "name": "DB_NAME", "value": "postgres" },
  { "name": "DB_USER", "value": "masteruser" },
  { "name": "DB_PASSWORD", "value": "YourStrongPassw0rd!" }
]


新しいリビジョンを登録 → vendor0919-task:4

aws ecs register-task-definition --cli-input-json file://td.json --region ap-northeast-1
aws ecs describe-task-definition --task-definition vendor0919-task --query "taskDefinition.revision" --region ap-northeast-1
# => 4


サービスを v4 に更新 & 再デプロイ

aws ecs update-service \
  --cluster vendor0919-cluster \
  --service vendor0919-service \
  --task-definition vendor0919-task:4 \
  --force-new-deployment \
  --region ap-northeast-1

6) RDS セキュリティグループの確認

ECS タスク SG: sg-023a5d27e13e2a967

RDS(Aurora) SG: sg-052aaf25ecb8c2e86

RDS 側 SG に インバウンド 5432/TCP で ソース SG=sg-023a5d27e13e2a967 を許可済みであることを確認：

aws ec2 describe-security-groups \
  --group-ids sg-052aaf25ecb8c2e86 \
  --region ap-northeast-1 \
  --query "SecurityGroups[0].IpPermissions"
# FromPort=5432, UserIdGroupPairs=[{ GroupId=sg-023a5d27e13e2a967 }]

7) FastAPI の動作確認（最終）
エンドポイント

ALB DNS: http://vendor0919-alb-1049264719.ap-northeast-1.elb.amazonaws.com

# ヘルス
curl http://vendor0919-alb-1049264719.ap-northeast-1.elb.amazonaws.com/health
# => {"status":"ok"}

# DB 接続
curl http://vendor0919-alb-1049264719.ap-northeast-1.elb.amazonaws.com/db-check
# => {"status":"ok","message":"DB connection successful"}


CloudWatch Logs にもヘルスチェック 200 OK が定期的に出ているのを確認。

付録：よく使った確認コマンド
# タスク一覧/状態
aws ecs list-tasks --cluster vendor0919-cluster --region ap-northeast-1
aws ecs describe-tasks --cluster vendor0919-cluster --tasks <taskId> \
  --region ap-northeast-1 --query "tasks[0].{lastStatus:lastStatus,health:healthStatus}"

# 停止理由
aws ecs describe-tasks --cluster vendor0919-cluster --tasks <taskId> \
  --region ap-northeast-1 --query "tasks[0].stoppedReason"

# ログ
aws logs describe-log-streams --log-group-name /ecs/vendor0919 \
  --order-by LastEventTime --descending --max-items 3 --region ap-northeast-1 \
  --query "logStreams[].logStreamName"

aws logs get-log-events \
  --log-group-name /ecs/vendor0919 \
  --log-stream-name <stream> \
  --region ap-northeast-1 \
  --limit 200 --no-start-from-head

学び / 落とし穴メモ

Exec は「有効化後に起動したタスク」でしか動かない（古いタスクは不可）

awslogs のロググループが無いとタスク即死（ResourceNotFoundException）

Python クライアント系は psycopg2-binary を requirements に入れるのが早い

環境変数はタスク定義に反映必須。未設定だと psycopg2 がローカルソケット(/var/run/postgresql)を見にいって迷子になる

NAT なしなら SSM/EC2Messages/SSMMessages の VPC エンドポイント必須（ECS Exec, Agent 通信用）

ALB ヘルスチェックは アプリの実装に合わせてパス調整（今回は /health）

