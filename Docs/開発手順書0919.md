ローカルとAWSを統合した実践マニュアル（Cursor + CloudShell）

Next.js + FastAPI ローカル開発 & AWSデプロイ 初心者マニュアル
はじめに (Introduction)

このマニュアルは、Next.js（フロントエンド）とFastAPI（バックエンド）を用いたWebアプリケーションをローカル環境で構築し、そのアプリをAWS上にデプロイする手順を初心者向けにまとめたものです。ローカル開発ではエディタ兼ターミナル環境として Cursor を使用し、AWS上での操作は CloudShell（AWSコンソール上のCLI環境） を用いる想定で記述しています。

 

構成：まずローカルでフロントエンド/バックエンドをゼロから構築し、ユーザー認証や検索APIなど基本機能を実装します。その後、AWSの各サービス（Amplify、ECR、ECS、ALBなど）を使ってフロントエンドをホスティングし、バックエンドをコンテナとしてデプロイします。最後に、開発・デプロイ中によく遭遇するエラーのトラブルシューティングや、運用上のTipsも紹介します。

 

前提技術：Next.js (React, TypeScript)、Tailwind CSS、shadcn/UI（UIコンポーネント）、FastAPI (Python)、SQLite (ローカルDB)、LangChain/Chroma (文章検索)、AWS Amplify、AWS ECS/Fargate、AWS ALB など。環境構築やコード記述の具体例を交え、初心者でも一つ一つ動作を確認しながら進められるよう解説します。

 

では、始めましょう。

ローカル開発環境の構築 (Local Development)
フロントエンドのセットアップ (Next.js + Tailwind + shadcn/UI)

1. Next.jsプロジェクトの作成：まずNext.jsの最新テンプレートをTypeScriptで作成します。ターミナル（Cursorのターミナル）で以下のコマンドを実行してください。

npx create-next-app@latest frontend --ts --eslint


プロンプトに従ってプロジェクト名（ここではfrontend）などを入力すると、Next.js 14（執筆時最新）の雛形プロジェクトが生成されます。

 

2. Tailwind CSSの導入：Next.jsプロジェクトのディレクトリへ移動し、Tailwind CSS関連のパッケージをインストール・初期化します。

cd frontend
npm install -D tailwindcss postcss autoprefixer  
npx tailwindcss init -p


生成された tailwind.config.js を開き、content 配列にソースコードディレクトリを指定します（例："./src/**/*.{js,ts,jsx,tsx}" や Next.js 13+ の場合は./app/**/*などを追加）。また、グローバルCSSファイル（src/app/globals.css など）に Tailwind のベース/コンポーネント/ユーティリティをインポートする記述を追記します:

/* globals.css の例 */
@tailwind base;
@tailwind components;
@tailwind utilities;


3. shadcn/UIの導入：次に、モダンなUIコンポーネントを素早く導入できるshadcn/UIを利用します。以下のコマンドでセットアップと基本コンポーネントの追加を行います 。

npx shadcn-ui@latest init       # shadcn/UIの初期化
npx shadcn-ui@latest add button input label  # ボタン・入力欄・ラベルを追加


これでUIライブラリの準備ができました。

 

4. ログインページの作成：ユーザーが認証できる画面を作るため、/loginページを実装します。Next.js App Router構造の場合、app/(auth)/login/page.tsx のようにディレクトリを作成することで認証系のルートを分離できます。page.tsxでは、先ほど追加したshadcnの<Input>, <Label>, <Button>等を用いてEmail入力欄、パスワード入力欄、ログインボタンを配置しましょう。ボタンのonClickやフォームのonSubmitハンドラで、まずはevent.preventDefault()を呼ぶ程度の簡易動作で構いません。

 

5. レイアウトとナビゲーション：ログインページを作ったら、共通レイアウトも設定します。app/layout.tsxにヘッダーやフッターを実装し、ログインページと今後作成するダッシュボードページへのリンクを設置します。ヘッダーにはアプリ名、フッターにはコピーライト表記などを入れておくとよいでしょう。また、App Routerの機能でレイアウト内にchildrenを表示することで各ページ共通の枠組みを作ります。

 

6. 起動確認：開発サーバーを起動し、ブラウザでhttp://localhost:3000/loginにアクセスして画面が表示されるか確認します 。

npm run dev


期待通りEmailとパスワードのフォームが表示されればOKです。この時点ではまだ認証ロジックは実装していないため、ボタンを押しても画面遷移は起きませんが、次のステップでこれを拡張します。

バックエンドのセットアップ (FastAPI)

フロントエンドと並行して、バックエンドAPIも構築します。ここではPython製の高速WebフレームワークであるFastAPIを使用します。

 

1. プロジェクト構成：フロントエンドプロジェクトと同じルートディレクトリに、新たにbackendというディレクトリを作成します。以降、backend内で開発を行います。Pythonの仮想環境を作り、必要ライブラリをインストールしましょう。

 

2. 仮想環境と依存インストール：ターミナルで以下を実行します。

# backend ディレクトリ内で:
python -m venv .venv        # 仮想環境の作成
source .venv/bin/activate   # 仮想環境を有効化 (Windowsの場合は .venv\Scripts\activate)
pip install fastapi uvicorn[standard] pydantic


FastAPI本体、開発サーバーのUvicorn、およびデータ検証用のPydanticがインストールされます。

 

3. FastAPIアプリの雛形作成：backendディレクトリ直下にmain.pyを作成し、以下の内容で編集します。

from fastapi import FastAPI

app = FastAPI()

@app.get("/health")
def health():
    return {"status": "ok"}


まずはFastAPI()のインスタンスを生成し、GET /healthエンドポイントだけを定義しています。ブラウザやcurlでアクセスするとJSON形式でステータスを返す簡単なAPIです。

 

4. CORS設定：ローカル開発ではフロントエンド（React）とバックエンド（FastAPI）が異なるポートで動作するため、ブラウザの同一生成元ポリシーによりリクエストがブロックされないよう**CORS (Cross-Origin Resource Sharing)**を許可する必要があります。FastAPIではStarletteのミドルウェアを使ってCORS許可が可能です。main.pyでFastAPIアプリ作成後、以下を追加しましょう。

from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # 開発中のフロントエンドの起源を許可
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


これで、http://localhost:3000 からのリクエストであれば、認証情報付きのものも含め全てのメソッド・ヘッダを受け付けるようになります。開発中はallow_origins=["*"]で全許可しても動作確認できますが、公開時には必要なドメインだけ許可するようにしましょう。

 

5. ロギング設定（オプション）：FastAPIのデフォルトログはINFOレベルでアクセスログなどが出力されます。特別な設定をしなくても動作しますが、必要に応じてloggingモジュールでloggerを取得し設定することも可能です。初心者はひとまずデフォルト設定のままで問題ありません。

 

6. バックエンドサーバー起動：Uvicornを使ってサーバーを起動します。

uvicorn main:app --reload --port 8080


main:app は main.py内のappオブジェクトを指しています。

--reload はコード変更時にホットリロードするオプションです。

--port 8080 でポート8080番を指定しています。

起動したら別のターミナルから curl http://127.0.0.1:8080/health を実行し、{"status":"ok"} が返ればバックエンドは正常に動作しています。ブラウザで http://127.0.0.1:8080/health にアクセスしても確認できます。

データベースの導入 (SQLite + SQLAlchemy + Alembic)

次に、ユーザー情報を保存するためにデータベースを組み込みます。開発環境では手軽に使えるSQLiteを使用し、本番では将来的にPostgreSQL（AWS RDS）へ移行することを想定します。

 

1. ライブラリのインストール：仮想環境下で以下をインストールします。

pip install sqlalchemy aiosqlite alembic passlib[bcrypt] python-dotenv


SQLAlchemy: PythonのORM（Object-Relational Mapper）でDB操作を簡潔にします。

aiosqlite: 非同期でSQLiteを扱うためのドライバ。SQLAlchemyと組み合わせて使います。

Alembic: データベースマイグレーションツール（DBスキーマの変更管理）。現時点では alembic init で初期化する程度でOKです。

passlib[bcrypt]: パスワードを安全にハッシュ化（bcrypt）するために使用します。ユーザーパスワードの保存に必須です。

python-dotenv: .env ファイルから環境変数を読み込むため。開発・本番で設定値を管理しやすくなります。

2. 環境変数ファイルの設定：backendディレクトリ直下に .env ファイルを作成し、データベース接続文字列などの設定を書きます。例えばSQLiteをカレントディレクトリのファイルで使う場合、以下を記載します:

DATABASE_URL=sqlite+aiosqlite:///./dev.db


これは「カレントフォルダの dev.db ファイルに接続せよ」という意味のURLです。FastAPIアプリ起動時にこの環境変数を読み取り、後でSQLAlchemyに渡します。必要に応じて .env に他の設定（後述のJWTシークレットなど）もまとめて記載していきます。

 

3. ユーザーモデルの定義：backend内にmodels.pyを作成し、SQLAlchemyでユーザー用のモデルを定義します。例えば:

from sqlalchemy import Column, Integer, String, DateTime
from sqlalchemy.orm import declarative_base
from datetime import datetime

Base = declarative_base()

class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True, index=True)
    email = Column(String, unique=True, index=True, nullable=False)
    password_hash = Column(String, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)


emailはユニーク制約を付け、同じメールアドレスで複数ユーザー登録できないようにします。

password_hashはハッシュ化されたパスワードを保存するカラムです。平文パスワードは絶対に保存しないでください。

created_atはレコード作成日時を記録しておきます。

4. データベース初期化：FastAPIアプリ起動時にテーブルを作成する処理を組み込みます。FastAPIの起動フローのどこかで以下を実行するとよいでしょう:

# 例: main.py内でアプリ起動後に実行
from . import models
from sqlalchemy import create_engine

engine = create_engine(os.environ["DATABASE_URL"])
models.Base.metadata.create_all(bind=engine)


これにより、まだ users テーブルが無ければ自動で作成されます。Alembicによる厳密なマイグレーション管理は将来必要になったときに導入しますが、開発初期では上記の簡易作成で問題ありません。

 

5. ユーザー登録APIの実装：ユーザーを登録するエンドポイントを作ります。FastAPIではリクエストボディをPydanticモデルで受け取るのが便利です。例えばschemas.pyに以下のようなモデルを定義します:

from pydantic import BaseModel

class UserCreate(BaseModel):
    email: str
    password: str


次に、認証用のAPIルータを作りましょう（例: auth.py または FastAPIのAPIRouterでモジュール化するとよいです）。ここではシンプルに説明のため main.py に直接書く例を示します。

from passlib.context import CryptContext
from sqlalchemy.orm import Session
from fastapi import Depends, HTTPException

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# 省略: DBセッション取得のDepends関数 get_db を用意しておく

@app.post("/auth/register", status_code=201)
async def register_user(user: UserCreate, db: Session = Depends(get_db)):
    # Email重複チェック
    existing = db.query(User).filter(User.email == user.email).first()
    if existing:
        raise HTTPException(status_code=409, detail="Email already registered")
    # パスワードハッシュ化して保存
    hash = pwd_context.hash(user.password)
    new_user = User(email=user.email, password_hash=hash)
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    return {"id": new_user.id, "email": new_user.email}
}


上記では、リクエストボディuserをPydanticモデルUserCreateで受け取り、すでに同じメールが登録済みなら409エラー、そうでなければpasslibでパスワードをbcryptハッシュ化してからユーザーを作成しています。ハッシュ化により、DBに保存されたパスワードから元の生パスワードを推測できなくなります。

 

6. ログインAPI（認証検証）の実装：登録済みユーザーがログインするためのAPIも作成します。例えば/auth/verifyエンドポイントをPOSTで設け、Emailとパスワードを受け取り、正しければユーザー情報を返すようにします。これもリクエストボディはPydanticモデルUserCreateを再利用できます。

@app.post("/auth/verify")
async def verify_user(user: UserCreate, db: Session = Depends(get_db)):
    db_user = db.query(User).filter(User.email == user.email).first()
    if not db_user or not pwd_context.verify(user.password, db_user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid credentials")
    # 認証成功時のレスポンス例（NextAuthと合わせるために追加情報を含める）
    return {"id": db_user.id, "email": db_user.email, "org_id": 1}


認証に失敗した場合は401 Unauthorizedを返し、成功した場合はユーザーIDやEmail等をJSONで返します。ここでorg_idは組織IDなどアプリ独自の情報を含める例です（必要に応じて省略可能）。

 

7. 動作確認（登録とログイン）：ターミナルから次のようにcurlで確認できます。

# 新規ユーザー登録（期待：201 Created）
curl -X POST "http://127.0.0.1:8080/auth/register" \
  -H "Content-Type: application/json" \
  -d '{"email": "alice@example.com", "password": "secret"}'

# ログイン試行（期待：200 OK または 401）
curl -X POST "http://127.0.0.1:8080/auth/verify" \
  -H "Content-Type: application/json" \
  -d '{"email": "alice@example.com", "password": "secret"}'


登録APIでは201ステータスと共に登録されたユーザーのidやemailが返り、続くverifyで正しい認証情報を送れば200とユーザー情報JSONが、間違った情報なら401エラーが返ることを確認してください。

 

※HTTP 422エラーに注意: FastAPIのエンドポイント定義で、クエリパラメータやフォームではなくJSONボディとして受け取りたい場合、上記のように関数引数をPydanticモデル（UserCreateなど）にする必要があります。例えば、誤ってasync def login_user(email: str, password: str):のように関数シグネチャでパラメータを定義すると、FastAPIはJSONではなくフォームデータとして受け取ろうとし、フロントからJSONを送るとHTTP 422 Unprocessable Entityエラーになります。このエラーはフロントとバックエンドのデータ形式の不一致で発生する典型例です。正しくPydanticモデル経由でJSONを受け取るように修正すれば解決します（詳細は後述のトラブルシューティング参照）。

認証機能のフロントエンド統合 (NextAuthによるログイン)

バックエンドに登録・認証APIができたので、フロントエンド側でこれを使ってログイン機能を実装します。Next.jsではNextAuth.jsというライブラリを使うと認証機能を簡単に構築できます。ここではCredentialsプロバイダを用いて、先ほどのFastAPI /auth/verify APIと連携させます。

 

1. NextAuth設定：Next.jsアプリ内に NextAuth のエンドポイントを設置します。App Routerの場合、app/api/auth/[...nextauth]/route.ts というファイルを作成し、NextAuthの設定を記述します。

// frontend/app/api/auth/[...nextauth]/route.ts
import NextAuth from "next-auth"
import CredentialsProvider from "next-auth/providers/credentials"

const NEXTAUTH_URL = process.env.NEXTAUTH_URL
const NEXTAUTH_SECRET = process.env.NEXTAUTH_SECRET

const handler = NextAuth({
  secret: NEXTAUTH_SECRET,
  providers: [
    CredentialsProvider({
      name: "Credentials",
      credentials: { email: { label: "Email" }, password: { label: "Password", type: "password"} },
      async authorize(credentials) {
        if (!credentials) return null
        // FastAPIの認証APIを呼び出し
        const res = await fetch(`${process.env.NEXT_PUBLIC_API_BASE}/auth/verify`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ email: credentials.email, password: credentials.password })
        })
        if (!res.ok) return null  // 認証失敗時
        const user = await res.json()
        return user  // 認証成功時、userオブジェクトを返す
      }
    })
  ]
})

export { handler as GET, handler as POST }


上記のように、NextAuthのCredentialsプロバイダ内でFastAPIの/auth/verifyにフェッチしています。認証OKならユーザー情報（ここでは{ id, email, org_id }）をuserとして返し、NGならnullを返しています。NextAuthは返ってきたuserオブジェクトをセッション情報としてJWTに含め、ブラウザのCookieにセッショントークンを保存します。

 

2. 環境変数の設定：NextAuthにはセキュリティのためシークレットキーが必要です。.env.local に以下を追記しましょう。

NEXTAUTH_SECRET=<ランダムな長い文字列>
NEXTAUTH_URL=http://localhost:3000    # 開発時のURL
NEXT_PUBLIC_API_BASE=http://127.0.0.1:8080


NEXTAUTH_SECRET はFastAPI側でも共有するシークレットで、JWTの署名に使われます。開発では適当な文字列（例: OpenSSL等で生成）で構いませんが、本番では十分長く複雑なものを使用します。この値はフロントとバックで必ず一致させます。

NEXTAUTH_URL はNextAuth用のアプリURLです。開発時はローカルホスト、本番ではホスト名を設定します。

NEXT_PUBLIC_API_BASE はフロントからバックエンドAPIを呼ぶ際のベースURLで、開発中はローカルFastAPI、本番ではデプロイ先のエンドポイントに変えます。環境変数名にNEXT_PUBLIC_が付くとブラウザ側でも参照可能になります。

3. ログインページでNextAuthを使用：既に作成した/loginページに、NextAuth経由で認証を行う処理を追加します。NextAuthにはReactフックやヘルパー関数が提供されており、例えば以下のように実装できます:

// frontend/app/(auth)/login/page.tsx （イメージコード）
"use client";

import { signIn } from "next-auth/react";

export default function LoginPage() {
  const handleLogin = async (email: string, password: string) => {
    const result = await signIn("credentials", {
      email, password, redirect: false
    });
    if (result?.ok) {
      // 認証成功 -> ダッシュボードへ遷移
      window.location.href = "/dashboard";
    } else {
      // 失敗 -> エラーメッセージ表示（省略）
    }
  };

  // フォームのJSX内で onSubmit={handleLogin(...)} を呼ぶ実装
}


上記は概略ですが、signIn("credentials") により、先ほど設定したCredentialsプロバイダ経由でFastAPI /auth/verify が呼ばれ、認証が行われます。結果がokであれば/dashboardページへ遷移させ、そうでなければエラー表示をする、といった流れです。

 

4. 認証状態に応じたルーティング：未ログインで/dashboardにアクセスできてしまうと問題なので、保護ルートの設定をします。Next.js App Routerではミドルウェアで保護する方法、または/dashboardレイアウトのサーバーコンポーネントでセッションを確認してリダイレクトする方法などがあります。簡単な方法はNext.jsのmiddleware機能を使うことでしょう。プロジェクトルートにmiddleware.tsを作成し、次のように書きます:

import { withAuth } from "next-auth/middleware";

export default withAuth({
  pages: {
    signIn: "/login"  // 未認証時にリダイレクトする先
  }
});

// 保護したいルートを指定（ここでは /dashboard 配下を保護）
export const config = { matcher: ["/dashboard/:path*"] };


これで、セッションが無い状態で/dashboard以下にアクセスすると自動的に/loginへリダイレクトされます。/dashboardに正常にアクセスできれば、NextAuthによるフロントエンドの認証導入は成功です。認証成功後の/dasbhoardページは現時点では空なので、次にダッシュボードUIを整えていきます。

 

5. ダッシュボード画面の骨格：ログイン後に表示するダッシュボードのUIを用意します。app/(app)/dashboard/page.tsx などにレイアウトを実装しましょう。shadcn/UIを使ってサイドバーやヘッダーを配置し、メニュー項目（Home, Vendors, Search, Settingsなど）を並べます。初めは中身が空でも構いません。これにより「ログイン -> ダッシュボード（空のページ）」まで一通りの流れが完成します。

JWTによる保護APIの実装 (FastAPI側)

NextAuthは標準でJWT(JSON Web Token)によるセッション管理を行います。フロントエンドではログイン成功時にJWTが発行され、以降のリクエストではこのJWTを含めることでユーザーの認証情報を引き継ぎます。バックエンド側でもこのJWTを検証し、保護されたエンドポイントでは正当なリクエストかチェックする仕組みを導入しましょう。

 

1. ライブラリのインストール：FastAPIでJWT検証を行うため、python-joseというライブラリを利用します（JWTのHS256署名検証を行う）。仮想環境で以下を実行します:

pip install python-jose[cryptography]


これによりJWTのエンコード/デコード機能が使えます。

 

2. 環境変数の設定：フロントエンドと同じNEXTAUTH_SECRETをFastAPI側でも使います。.envに以下を追加します（フロントと同じ値にすること）:

NEXTAUTH_SECRET=<上で設定したシークレットと同じ値>


FastAPI起動時にpython-dotenvで環境変数をロードしていれば os.environ["NEXTAUTH_SECRET"] などで参照できます。

 

3. ユーザー認証ヘルパー関数の実装：JWTを検証し、ユーザー情報を取得する関数を作成します。例えばsecurity.pyを作り、以下のように書きます:

from jose import JWTError, jwt
from fastapi import Header, HTTPException, Depends

SECRET = os.environ["NEXTAUTH_SECRET"]
ALGORITHM = "HS256"

def get_current_user(authorization: str = Header(...)):
    """AuthorizationヘッダのBearer JWTからユーザー情報を取得"""
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid auth header")
    token = authorization[len("Bearer "):]
    try:
        payload = jwt.decode(token, SECRET, algorithms=[ALGORITHM])
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid or expired token")
    # ペイロードから必要な情報を取り出す
    user_id: str = payload.get("id")  # NextAuthのJWTには user.id 等が含まれる
    org_id: int = payload.get("org_id")
    if user_id is None:
        raise HTTPException(status_code=401, detail="Invalid token payload")
    return {"user_id": user_id, "org_id": org_id}


上記では、HTTPヘッダAuthorization: Bearer <JWT>を受け取り（FastAPIのDepends機能でヘッダを取得しています）、python-joseのjwt.decode関数でHS256検証を行っています。NEXTAUTH_SECRETを使っている点が重要です。JWTの署名が正しく、デコードできればペイロード（中にid, email, org_id等が含まれる想定）を取り出します。不正な場合は401エラーを投げます。

 

4. 保護エンドポイントの追加：例えばログインユーザーの情報を取得する /me APIを作り、上記認証ヘルパーを適用してみます。FastAPIではDependsを使ってエンドポイント関数に渡せば認証が自動的に適用されます。

from .security import get_current_user

@app.get("/me")
def get_me(current = Depends(get_current_user)):
    # current には {'user_id': ..., 'org_id': ...} が入る想定
    return {"message": f"Hello User {current['user_id']} of Org {current['org_id']}"}


これで /me エンドポイントにアクセスがあった際、get_current_userが先に実行され、検証エラーなら即401が返ります。成功すればユーザー情報を取得した上で処理が行われ、例えば上記ではシンプルにユーザーIDと組織IDを含むメッセージを返しています。

 

5. 動作確認：有効なJWTを持つ状態で/meを呼ぶと200 OKが返り、JWTなしまたは改ざんされたJWTでは401が返ることを確認します。JWTはNextAuthが自動付与しますが、手動で試すにはChromeのDevToolsなどでログイン後のJWTを取り出すか、NextAuthのJWTの有効期間を長めに設定した上で取得する方法があります。簡易確認として、あえてget_current_user内で署名検証部分をコメントアウトしpayload = jwt.get_unverified_claims(token)で試すなどの方法もありますが、本番では必ず検証しましょう。

 

もしJWT検証でハマる場合：例えば「フロントでログインできているのにFastAPI側では常に401になる」場合、以下をチェックしてください:

NextAuthのJWTシークレットがFastAPIと一致しているか

JWTの署名アルゴリズム（HS256）に相違がないか（NextAuthはデフォルトHS256）

FastAPI側で正しいヘッダ名・トークン部分を取得できているか（Authorizationの綴りなど）

以上で、バックエンド側でもJWTを用いてリクエストの認可が行えるようになりました。これで「ログイン→JWT発行→保護APIアクセス」という一連の認証フローがローカルで完成しました。

質問応答機能の実装 (シンプルRAGによる検索API)

最後に応用として、Markdown文書からAIが回答を検索するRAG (Retrieval-Augmented Generation) 機能を組み込みます。これは応用的な内容なので、最初はモック（ダミー応答）でも構いませんが、ここではLangChainなどを使った具体的な実装手順を概説します。

 

1. ライブラリのインストール：バックエンド仮想環境で以下を追加インストールします。

pip install langchain chromadb langchain-openai


LangChain: 複数のLLM操作をチェーンするライブラリ。

ChromaDB: シンプルに使えるベクトルデータベース（埋め込みの近似検索に使用）。

langchain-openai: OpenAIの埋め込みモデルやLLMを使うためのLangChain拡張。

2. データのインデックス作成：検索対象となるMarkdownドキュメント群を用意し、埋め込みインデックスを構築します。例えばrag/ingest.pyのようなスクリプトを作成します。

from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# Markdownファイルの読み込み
loader = DirectoryLoader("./docs", glob="*.md")
documents = loader.load()

# ドキュメントを分割（長すぎる文章は適度な長さに）
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
docs = text_splitter.split_documents(documents)

# ベクトル埋め込み生成（OpenAI APIキーが必要）
embeddings = OpenAIEmbeddings(openai_api_key=os.environ["OPENAI_API_KEY"])
vectordb = Chroma.from_documents(docs, embedding=embeddings, persist_directory="./chroma_index")

# インデックスをディスクに保存
vectordb.persist()


上記では、./docsディレクトリにあるMarkdown (*.md)を全て読み込み、約1000文字ごとにオーバーラップしながら分割しています。そしてOpenAIの埋め込みモデルを使いベクトル化し、ChromaDBに保存しています。実行にはOpenAIのAPIキーが必要なので、.envに OPENAI_API_KEY=<Your API Key> を追加しておきましょう。

 

3. 質問検索APIの実装：FastAPIに質問を受け取って関連する文書を検索し、言語モデルで回答を生成するエンドポイントを作ります。LangChainを使うと、簡潔に実装できます。例えばrouters/search.pyに以下のような内容を書きます:

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from langchain.vectorstores import Chroma
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA

router = APIRouter()

class SearchRequest(BaseModel):
    query: str
    k: int = 4              # 取得する類似文書数
    use_mmr: bool = False   # MMR(Maximal Marginal Relevance)使うか

@router.post("/search")
async def search(req: SearchRequest):
    # ChromaDBからベクトルストアを読み込み
    vectordb = Chroma(persist_directory="./chroma_index", embedding_function=OpenAIEmbeddings())
    retriever = vectordb.as_retriever(search_kwargs={"k": req.k, "maximal_marginal_relevance": req.use_mmr})
    # LLM+Retrieverのチェーンを構築
    qa_chain = RetrievalQA.from_chain_type(
        llm=OpenAI(model_name="gpt-3.5-turbo", openai_api_key=os.environ["OPENAI_API_KEY"]),
        chain_type="stuff", retriever=retriever,
        return_source_documents=True
    )
    result = qa_chain({"query": req.query})
    # 回答と参照文献を整形して返す
    answer = result["result"]
    sources = []
    for doc in result["source_documents"]:
        sources.append({"title": doc.metadata.get("source", "source"), "url": doc.metadata.get("source", ""), "score": doc.score})
    return {"answer": answer, "sources": sources}
}


このコードでは、保存しておいたChromaのベクトルストアから似た文書を検索し、OpenAIのChatモデルを使って質問への回答を生成しています。sourcesには引用元のタイトルやURL、スコアを入れています。ChatGPTに事前にプロンプトを工夫し、回答文中に引用を含めるよう指示することもできます。ここでは簡略化のため省いています。

 

4. エンドポイントの登録：上記のAPIRouterをメインのFastAPIアプリに組み込みます。main.pyで以下のように追加します:

from .routers import search_router
app.include_router(search_router)


5. 動作確認：FastAPIを再起動し、例として以下のようなリクエストを投げます。

curl -X POST "http://127.0.0.1:8080/search" \
  -H "Content-Type: application/json" \
  -d '{ "query": "FastAPIでCORSエラーが出る原因は？", "k": 4, "use_mmr": true }'


結果として、answerに回答文、sourcesに参照文献の配列が含まれたJSONが返ってくれば成功です。もし関連する文書が見つからない場合、スコアが低く「わからない」という趣旨の回答が返るようにするなど工夫も可能です。

 

**(※)**最初はLangChainのセットアップが難しい場合、/searchはダミーの固定レスポンスを返すよう実装し、まずはフロントエンドとの接続を確認してから本格実装に移るのも一つの方法です。

フロントエンドとバックエンドの接続 (検索UIの実装)

最後に、フロントエンド側に検索画面を作り、先ほどの /search APIを呼び出して結果を表示してみましょう。

 

1. 環境変数の確認：.env.localに NEXT_PUBLIC_API_BASE が設定されていることを再確認します（開発では http://127.0.0.1:8080） 。これが正しく設定されていないとフロントからバックエンドへのリクエストURLが間違ってしまいます。

 

2. API呼び出し関数の作成：フロントエンドのコード（Next.js）からバックエンドを呼び出す関数を作ります。例えばsrc/lib/api.tsのようなユーティリティモジュールに以下の関数を用意します:

// frontend/src/lib/api.ts
export const API_BASE = process.env.NEXT_PUBLIC_API_BASE!;

export async function searchQuery(query: string, k: number = 4, mmr: boolean = false) {
  const res = await fetch(`${API_BASE}/search`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    credentials: "include",  // 認証Cookieを含める場合
    body: JSON.stringify({ query, k, use_mmr: mmr })
  });
  if (!res.ok) {
    throw new Error(`API error: ${res.status}`);
  }
  return res.json();
}


これでフロントから /search を簡単に呼べるようになります。

 

3. 検索ページの実装：app/(app)/dashboard/search/page.tsx を作成し、検索フォームと結果表示用のUIを構築します。フォームには少なくとも質問入力欄、およびk（何件の文献を使うか）やMMRオン/オフのチェックボックスなどを配置します。検索ボタンが押されたら上記のsearchQuery関数を呼び、結果が戻ったら回答テキストと引用ソース一覧を画面に表示します。

 

UI実装にはshadcn/UIのコンポーネントを活用できます。例えば結果表示にはカードコンポーネントを使い、回答を表示、その下に引用元一覧（タイトルとURL、オプションでスコア）をリンク付きで列挙します。検索中はSkeleton（灰色のプレースホルダ）を表示し、エラー時はToastで通知する、といったユーザビリティ向上も取り入れてみましょう。

 

4. 認証考慮：/dashboard/searchページ自体はmiddlewareで保護されているためログイン済みユーザーしかアクセスできません。それでも念のため、APIレスポンスで401や403（未認可）が返ってきた場合にはwindow.location.href = "/login"するなど対処しておくと良いでしょう。

 

5. 動作確認：フロントエンドの開発サーバー(npm run dev)とバックエンドのUvicornを両方起動し、ブラウザでhttp://localhost:3000/loginからログイン、メニューからSearchページを開いて適当な質問を入力してみます。数秒待つと回答と引用がカードに表示されれば成功です 。kの値やMMRチェックのオンオフで結果が変わる（引用数や内容が多少変化する）のも確かめてみてください。

 

以上で、ローカル開発環境でフロントエンド→バックエンド→データベース/AIまで一通り繋がったアプリケーションが完成しました。
まとめると:

フロントエンド: Next.js + Tailwind + shadcn/UIでUI構築、NextAuthで認証管理。

バックエンド: FastAPI + SQLiteでAPI構築、JWTで保護、LangChainで検索機能。

両者はHTTPで通信し、CORS許可と環境変数設定(NEXT_PUBLIC_API_BASE)によって連携。

ローカルで十分テストできたら、いよいよこれをAWS上にデプロイして公開してみましょう。

AWSへの構築・デプロイ (AWS Deployment)

ローカルで動くアプリケーションが完成したら、次はクラウド上に公開するステップです。ここではフロントエンドはAWSのマネージドサービスである Amplify Hosting を使ってデプロイし、バックエンドはコンテナ化して ECS (Elastic Container Service) のFargateにデプロイする構成をとります。以下、AWSの各サービス設定を進めていきます。AWS作業は基本的に AWSコンソール内のCloudShellを起動してCLIコマンドを実行する形で説明します。CloudShellはAWS CLIが使えるLinux環境なので、ローカルでAWS CLIを設定する代わりに利用できます。

※この項ではAWSリソース名やIDは各自の環境に合わせて適宜置き換えてください。文中の <YOUR_...> と記載した箇所には、自身のAWSアカウントIDやドメイン名等を読み替えて入力してください。

フロントエンドのデプロイ設定 (AWS Amplify)

フロントエンド（Next.js）は静的サイトとしてビルドし、Amplify Hostingでホスティングします。Amplifyを使うと、GitHub連携による継続的デプロイやカスタムドメインの設定も簡単に行えます。

 

1. Amplifyアプリの作成: AWSマネジメントコンソールでAmplifyのページに移動し、「新規アプリのホスティング」を選択します。

リポジトリ: GitHubを選択し、対象のリポジトリを接続（例: your-account/your-repo の mainブランチ）します。モノレポの場合、後で設定を調整します。

アプリ名: 適当な名前を付けます（例: myapp-frontend）。

ビルド設定: Amplifyが自動検出した設定をもとに進めます。Next.jsであればデフォルトのbuild command(npm run build)とpublishディレクトリ(.next)が選択されます。

環境変数: Amplifyの設定画面で、ビルド時に必要な環境変数を指定します。少なくとも、フロントエンドがバックエンドを呼ぶURLを指定するために NEXT_PUBLIC_API_BASE (または NEXT_PUBLIC_API_URL) を設定しましょう。現時点ではバックエンドのエンドポイントが未定の場合、一旦プレースホルダで構いません（例: https://<YOUR_API_DOMAIN>）。この値は後から変更できます 。

Amplifyの初回デプロイを実行すると、GitHubのmainブランチからコードを取得し、npm ci→npm run build→ビルド成果物をS3ホスティングという一連の処理が自動で行われます。正常にいけば数分で「デプロイ完了」となり、Amplifyが提供するURLでアプリが表示されます（例: https://main.abcd1234.amplifyapp.com） 。

 

2. カスタムドメインの設定（任意）: AmplifyのホスティングURLはランダムなサブドメインになりますが、独自ドメイン（例: app.example.com）で公開したい場合は、Amplifyの「ドメイン管理」で独自ドメインを接続します。AWSのRoute 53でドメインを管理していれば、Amplifyが自動的にACM証明書を発行しHTTPS化まで行ってくれます。手順としては:

Amplify設定でドメインを追加し、案内に従ってDNSのCNAMEレコードを設定。

SSL証明書の検証が完了すると、自動的にAmplifyのカスタムドメインが有効になります。

3. Amplifyデプロイのトラブルシューティング: Amplifyでよく起こり得る問題と解決策をいくつか共有します:

ビルドエラー（依存関係の不整合）: npm ciでパッケージインストールが失敗する場合、package-lock.jsonが壊れている可能性があります。ローカルで一度npm installし、lockファイルを更新してコミットし直すと改善することがあります。

ビルド成果物が見つからない: Amplifyのビルド設定でartifacts > baseDirectoryが正しく指定されていないと404になります。Next.jsの場合はビルド出力先は.nextディレクトリです。monorepoでfrontend/.nextなどにしている場合も、AmplifyのappRoot設定（後述）と組み合わせ正しく指定しましょう。

環境変数の設定漏れ: APIのURLなど環境変数をAmplify側に設定し忘れると、ビルドは通っても動的呼び出しが失敗します。Amplifyコンソールの「環境変数」セクションに必要なキーを追加して再デプロイしてください。

モノレポ構成の場合の404: フロントエンドコードがリポジトリのサブフォルダ（例: /frontend）にある場合、Amplifyはそれをモノレポと認識します。amplify.yml に適切な applications 設定を入れないとデプロイ後に404エラーになります。解決策として、Amplifyのビルド設定ファイルを以下のように修正します:

version: 1
applications:
  - appRoot: frontend       # フロントエンドプロジェクトのルートを指定
    frontend:
      phases:
        preBuild:
          commands:
            - nvm install 20   # Node.jsバージョンの指定（必要に応じて）
            - nvm use 20
            - npm ci
        build:
          commands:
            - npm run build
      artifacts:
        baseDirectory: .next
        files:
          - '**/*'
      cache:
        paths:
          - node_modules/**/*
          - .next/cache/**/*


またAmplify設定の環境変数に AMPLIFY_MONOREPO_APP_ROOT=frontend を追加し、差分デプロイを無効化する場合は AMPLIFY_DIFF_DEPLOY=false も設定します。この設定によりAmplifyがモノレポ構成を正しくビルドできるようになります（CustomerError: Monorepo spec provided without "applications" key等のエラーが解消します）。

Amplifyの設定とデプロイが完了すれば、フロントエンドはインターネット経由でアクセス可能になります。次はバックエンドAPIをデプロイして、フロントエンドから呼べるようにしましょう。

バックエンドのコンテナ化とECRプッシュ (Containerize Backend & Push to ECR)

FastAPIバックエンドをAWS上で動かすには、コンテナ化してECSサービスとして動かすのが手軽です。まずはDockerイメージを作成し、ECR (Elastic Container Registry) にプッシュします。

 

1. Dockerfileの作成: backendディレクトリに Dockerfile を用意します。内容は以下のようになります。

# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 依存ライブラリがOSパッケージに依存する場合は以下で追加 (必要に応じて)
# RUN apt-get update && apt-get install -y gcc make ...

COPY . .
EXPOSE 8080
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]


ポイントは、FastAPIを8080ポートで起動することです。後述するAWSのFargate環境ではコンテナポート8080経由でALBからヘルスチェックする設定とするため、ここを8080にしています（どのポートでもよいですが、記事内では8080で統一しています）。

 

また、requirements.txtにはFastAPIプロジェクトに必要なすべてのパッケージを漏れなく記載しておきます。例えば前述のDBやJWT関連なら以下のようになります:

fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic[email]==2.5.0
sqlalchemy==2.0.23
aiosqlite==0.19.0
alembic==1.11.1
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0
python-jose[cryptography]==3.3.0
python-multipart==0.0.6
email-validator==2.1.0
langchain==0.0.XXX        # （任意）RAG機能実装に使う場合
openai==0.XX.X            # （任意）同上
chromadb==0.XX.X          # （任意）同上


2. Dockerイメージのビルドとテスト: ローカル環境またはCloudShell上でDockerビルドします。ここではCloudShellを使って進めます（初めてCloudShellを使う場合は最大60秒ほど環境準備に時間がかかることがあります）。CloudShellを開いたら、まずソースコードを配置しましょう。GitHubにコードがある場合は git clone で取得するか、ZIPアップロードなどでCloudShell上にfrontend/とbackend/ディレクトリを用意します。AWSアクセスキー等はCloudShellでは不要です（既に認証済み環境のため）。

 

CloudShellで以下を実行します:

# CloudShellにて、backendディレクトリに移動してから:
docker build -t myapp-api:latest .
docker run -d -p 8080:8080 --name myapp-api-test myapp-api:latest


docker build: ローカル（CloudShell上）で myapp-api:latest というタグのDockerイメージをビルドします。

docker run: ビルドしたイメージをコンテナとして起動し、ホストの8080ポートにマップします。

コンテナが起動したら、curl http://localhost:8080/health を実行し、{"status":"ok"} が返ることを確認します。問題なく起動していれば、コンテナを停止・削除しましょう:

docker stop myapp-api-test && docker rm myapp-api-test


3. ECRリポジトリの作成: AWSコンソールのECR (Elastic Container Registry) セクションでプライベートリポジトリを作成します。ここでは例としてmyapp-apiという名前にします。あるいは、AWS CLIで以下を実行しても作成可能です（CloudShell上で実行可）:

aws ecr create-repository --repository-name myapp-api --region <YOUR_AWS_REGION>


作成が成功すると、AWSアカウントIDとリージョンに対応したリポジトリURI（例: <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.ap-northeast-1.amazonaws.com/myapp-api）が払い出されます。

 

4. ECRへのDockerイメージpush: ビルドしたイメージをECRに登録します。ECRはプライベートレジストリなので、pushするには一時認証トークンを取得してDockerにログインする必要があります。CloudShellで以下を実行します:

# 1) ECRへDockerログイン
aws ecr get-login-password --region <YOUR_AWS_REGION> \
  | docker login --username AWS --password-stdin <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_AWS_REGION>.amazonaws.com

# 2) イメージにECR用タグを付与
docker tag myapp-api:latest <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_AWS_REGION>.amazonaws.com/myapp-api:latest

# 3) ECRへpush
docker push <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<YOUR_AWS_REGION>.amazonaws.com/myapp-api:latest


1)でdocker loginが成功すると「Login Succeeded」と表示されます。2)でECRのリポジトリURIをタグに付け、3)で実際にプッシュします。サイズによりますが、数十秒～数分で完了するでしょう。

ℹ️ メモ: フロントエンドもコンテナでデプロイする場合、同様にDockerfileを作ってECRにプッシュする手順が必要です。しかしここではAmplifyでホスティングしているため、無理にコンテナ化する必要はありません。CodeBuildなどを用いたコンテナ自動ビルドについてはTipsで触れます。

ECSクラスタとサービスの設定 (ECS Fargate)

AWSでコンテナを実行するにはECSを使います。Fargateを選べばサーバーレスにコンテナを動かせます。以下、コンソールおよびCLIで主要リソースを設定していきます。

 

1. ECSクラスターの作成: ECSのコンソールから「クラスターの作成」を行います。ネットワーキングのみのテンプレートを使い、Fargate対応のクラスターを作ります。デフォルトVPCとサブネットの作成オプションを有効にすると、自動で適切なVPC環境が整います。クラスター名は例としてmyapp-clusterとします。

 

（既存のVPCを使う場合は、パブリックサブネットが2つ以上あることを確認してください。ALBを利用するには異なるAZに属する2つのサブネットが必要です。）

 

2. タスク定義の作成: タスク定義とは、コンテナをどの設定で動かすかを記述したテンプレートです。ECSコンソールで「タスク定義の作成」->「Fargate」を選び、以下を設定します。

タスク定義名: 例 myapp-api-task

タスクロール: （必要に応じて）データベースやシークレットにアクセスするならIAMロールを指定しますが、今は空でOK。

ネットワークモード: awsvpc（デフォルト）

Task size: CPU 0.25 vCPU (256) / メモリ 0.5GB (512) 程度から。必要に応じ調整します。

次にコンテナ定義を追加します。ECRに登録したイメージURIを指定し、ポートは先ほどDockerfileでEXPOSEした8080をコンテナポートに入れます。例えば:

コンテナ名: api

イメージ: <YOUR_AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com/myapp-api:latest

ポート番号: 8080 (プロトコルTCP)

(任意)「Advanced container configuration」で以下も設定可能です:

環境変数: ハードコードしたい環境変数 (.env相当) があればここで定義。ただしシークレット値（DBパスワードやAPIキーなど）は絶対に直書きせず、代わりにSecretsの欄でSecureStringを指定しましょう。例えばAWS Secrets ManagerにOPENAI_API_KEYなどを事前に登録しておき、ここで参照する形です。

ヘルスチェック: コンテナ内部のHTTPヘルスチェックを設定します。CMD-SHELLでcurl -f http://localhost:8080/health || exit 1のように指定し、Interval 30秒・Timeout 5秒・Retries 3・StartPeriod 10秒くらいに設定するとよいでしょう。

ログ: ログドライバをawslogsにしてロググループを指定すると、コンテナ標準出力がCloudWatch Logsに送られます。ロググループは例えば/ecs/myapp-apiなど。先にCloudWatch Logsでグループを作っておくか、/ecs/clusterName/containerName形式で自動作成されます。

以上入力できたらタスク定義を作成します（コンソールでは「作成」ボタン）。CLIでJSON定義する場合は次のような内容になります（一部抜粋、環境値やARNは自分の値に置換してください）:

{
  "family": "myapp-api-task",
  "networkMode": "awsvpc",
  "executionRoleArn": "arn:aws:iam::<YOUR_AWS_ACCOUNT_ID>:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::<YOUR_AWS_ACCOUNT_ID>:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "api",
      "image": "<YOUR_AWS_ACCOUNT_ID>.dkr.ecr.ap-northeast-1.amazonaws.com/myapp-api:latest",
      "portMappings": [ { "containerPort": 8080, "protocol": "tcp" } ],
      "essential": true,
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"],
        "interval": 30, "timeout": 5, "retries": 3, "startPeriod": 10
      },
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": { "awslogs-group": "/ecs/myapp-api", "awslogs-region": "<REGION>", "awslogs-stream-prefix": "ecs" }
      },
      "environment": [ {"name": "PORT", "value": "8080"} ],
      "secrets": [
        {"name": "NEXTAUTH_SECRET", "valueFrom": "arn:aws:secretsmanager:<REGION>:<ACCOUNT_ID>:secret:NEXTAUTH_SECRET-<ID>"},
        {"name": "OPENAI_API_KEY", "valueFrom": "arn:aws:secretsmanager:<REGION>:<ACCOUNT_ID>:secret:OPENAI_API_KEY-<ID>"}
      ]
    }
  ],
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "256",
  "memory": "512"
}


上記JSONを taskdef.json として保存し、CloudShellで登録することもできます:

aws ecs register-task-definition --cli-input-json file://taskdef.json --region <REGION>


3. ECSサービスの作成: 次に、クラスター上でタスクを動かす サービス を作成します。ECSコンソールから該当クラスターを開き、「サービスの作成」を選択、以下を設定します。

起動タイプ: Fargate

タスク定義: 上で作成したものを選択（最新版が自動選択されます）。

プラットフォームバージョン: Latest (1.4.0 など)

クラスター: myapp-cluster

サービス名: 例 myapp-api-service

タスク数: とりあえず1（必要に応じ後でスケールアウト可能）

ネットワーキング設定:

デプロイタイプ: 「ローリング更新」を選択します（後でBlue/Greenも紹介します）。

ネットワーク: 先ほど作成/選択したVPC

サブネット: パブリックサブネットを2つ（ALB経由にする場合、通常タスク自体はプライベートでOKですが、ここではデバッグしやすさのため一旦パブリックにします）。

セキュリティグループ: 新規にecs-sg等を作成し、外部アクセスは不要なのでとりあえずインバウンド空（後でALBからのみ受ける設定にします）。

ロードバランサの設定: ここでは一旦「ロードバランサなし」として進めます（後でALBと繋ぐため）。

「サービスの作成」を実行すると、ECSが指定のタスクを起動しようとします。数分以内にタスクが起動し、ステータスが「Running」になれば成功です。ですが現在はロードバランサを付けていないため外部アクセス手段がありません。CloudShellから以下を実行し、タスクのパブリックIPを取得して疎通確認してみましょう。

# タスクIDを取得
TASK_ARN=$(aws ecs list-tasks --cluster myapp-cluster --service-name myapp-api-service --query "taskArns[0]" --output text)
# ENI（Elastic Network Interface）IDを取得
ENI_ID=$(aws ecs describe-tasks --cluster myapp-cluster --tasks $TASK_ARN --query "tasks[0].attachments[0].details[?name=='networkInterfaceId'].value" --output text)
# パブリックIP取得
PUBLIC_IP=$(aws ec2 describe-network-interfaces --network-interface-ids $ENI_ID --query "NetworkInterfaces[0].Association.PublicIp" --output text)
echo "Task Public IP = $PUBLIC_IP"
# /healthにアクセスしてみる
curl http://$PUBLIC_IP:8080/health


上記でもし{"status":"ok"}が取得できれば、コンテナは正常に稼働しています。セキュリティグループのインバウンドが空っぽの場合はタイムアウトになるので、一時的にSGにポート8080の0.0.0.0/0許可を入れて試すとよいでしょう。CloudShellでSG開放するには次のようにします（※デプロイ後は外してALB経由にします）:

aws ec2 authorize-security-group-ingress \
  --group-id <ECS_TASK_SG_ID> \
  --protocol tcp --port 8080 --cidr 0.0.0.0/0

アプリケーション負荷分散 (ALB) の設定

ECSのタスクを外部公開するには、Application Load Balancer (ALB) を使うのが一般的です。ここではALBを新規作成し、先のECSサービスと紐付けます。

 

1. ALBの作成: CloudShellで以下のコマンドを実行し、ALB本体を作成します。必要なパラメータはVPC ID（先のECSクラスター用に使ったVPC）と、そのVPC内の2つのサブネットです（別AZになるよう選ぶ）。セキュリティグループもここで指定します。ALB用に新たにSGを作成し、インバウンドでHTTP(80)およびHTTPS(443)を0.0.0.0/0から許可しておきます。作成コマンド例:

export VPC_ID=<YOUR_VPC_ID>
export SUBNET_1=<YOUR_SUBNET_ID_1>
export SUBNET_2=<YOUR_SUBNET_ID_2>
export ALB_SG_ID=<YOUR_ALB_SG_ID>
aws elbv2 create-load-balancer \
  --name myapp-alb \
  --subnets $SUBNET_1 $SUBNET_2 \
  --security-groups $ALB_SG_ID \
  --scheme internet-facing \
  --type application \
  --region <REGION>


成功するとALB ARNとDNS名が返されます。以降、ALB ARNを環境変数に入れておくと便利です。

export ALB_ARN=<上記で作成されたALBのARN>


2. ターゲットグループの作成: 次に、ALBがトラフィックを流す先のターゲットグループ(TG)を作ります。ECS(Fargate)の個々のタスクはIPでターゲット登録するので、TGタイプはipを選びます。ポートはECSコンテナのポート8080に合わせます。コマンド例:

aws elbv2 create-target-group \
  --name myapp-tg-8080 \
  --protocol HTTP --port 8080 \
  --target-type ip \
  --vpc-id $VPC_ID \
  --region <REGION>


これもTG ARNが返るので変数に入れます:

export TG_ARN=<作成されたTGのARN>


デフォルトではヘルスチェックパスが「/」になっているので、FastAPIのヘルスエンドポイントに合わせて修正します:

aws elbv2 modify-target-group \
  --target-group-arn $TG_ARN \
  --health-check-path "/health" \
  --health-check-port "traffic-port" \
  --health-check-protocol HTTP \
  --healthy-threshold-count 2 \
  --unhealthy-threshold-count 2 \
  --matcher HttpCode=200 \
  --region <REGION>


3. リスナーの作成: ALBが受け付けるポートとターゲットグループの関連付けを行います。まずはHTTP(80)で作り、後で必要ならHTTPSリスナーを追加します。コマンド:

aws elbv2 create-listener \
  --load-balancer-arn $ALB_ARN \
  --protocol HTTP --port 80 \
  --default-actions Type=forward,TargetGroupArn=$TG_ARN \
  --region <REGION>


4. ECSサービスへALBを登録: 既存のECSサービス（myapp-api-service）にALBを組み込みます。CLIで以下を実行します:

aws ecs update-service \
  --cluster myapp-cluster \
  --service myapp-api-service \
  --load-balancers "targetGroupArn=$TG_ARN,containerName=api,containerPort=8080" \
  --region <REGION>


これでECSサービスはALB経由で流入する設定になります。あわせて、ECSタスクのセキュリティグループに「ALBからのアクセスを許可」するルールを追加します。もしALB用SGとECS用SGを別々にしているなら、ECS側SGのインバウンドに「ソース = ALBのSG, ポート8080許可」のルールを設定します。SGが同じ場合はself参照の許可が必要です。例:

# ALBとECSタスクで同一SGを使っている場合の自己参照許可:
aws ec2 authorize-security-group-ingress \
  --group-id $ALB_SG_ID \
  --protocol tcp --port 8080 \
  --source-group $ALB_SG_ID \
  --region <REGION>


5. 動作確認: ALB経由でバックエンドにアクセスできるか確認します。ALBのDNS名を取得しましょう。

aws elbv2 describe-load-balancers \
  --load-balancer-arn $ALB_ARN \
  --query "LoadBalancers[0].DNSName" --output text --region <REGION>


上記で例えば myapp-alb-123456789.ap-northeast-1.elb.amazonaws.com のようなDNS名が得られます。これに対し、ローカルから curl http://<ALB_DNS_NAME>/health を実行してみてください。{"status":"ok"} が返れば成功です。

Tip: ALBのターゲットのヘルスチェックがinitialからhealthyになるまで1～2分かかることがあります。先にcurlしてダメでも少し待ってから再度試してみましょう。

6. Amplify側のAPI先URLを更新: バックエンドがALB経由でインターネット公開できたので、Amplifyホスト中のフロントエンドからこのAPIを呼ぶよう設定します。AmplifyでNEXT_PUBLIC_API_BASE環境変数を上書きする手順です。CloudShellで以下を実行します（AmplifyのApp IDとブランチ名が必要。Amplifyコンソールの設定画面で確認可能です）:

export AMPLIFY_APP_ID=<YOUR_AMPLIFY_APP_ID>
export AMPLIFY_BRANCH=main
aws amplify update-branch \
  --app-id $AMPLIFY_APP_ID \
  --branch-name $AMPLIFY_BRANCH \
  --environment-variables NEXT_PUBLIC_API_BASE=http://<ALB_DNS_NAME> \
  --region <REGION>
aws amplify start-job \
  --app-id $AMPLIFY_APP_ID \
  --branch-name $AMPLIFY_BRANCH \
  --job-type RELEASE \
  --region <REGION>


これでAmplifyの再デプロイが走り、フロントエンドのAPI先が新しいエンドポイントに差し替わります。デプロイ完了後、AmplifyのURL（または設定した独自ドメイン）でアプリにアクセスし、ログイン〜検索機能まで一通り動作するか確認しましょう。Amplify側でCORSエラーが出る場合、バックエンドFastAPIのCORS設定にAmplifyのドメイン(例: https://app.example.com)を追加するのをお忘れなく 。

 

ここまでで、本番相当の環境にフロントエンドとバックエンドがデプロイできました。以下では、運用上出会うかもしれない問題への対処法や、さらに発展的な設定について触れます。

トラブルシューティング (Troubleshooting)

開発からデプロイにかけて直面しがちなエラーとその解決策をいくつか紹介します。問題の原因分析から対応、そして得られた教訓までまとめます。

ケース1: FastAPIの認証APIでHTTP 422エラーが発生

発生状況: Next.jsのログインフォームからFastAPIの/auth/verifyをPOSTで呼び出したところ、レスポンスがHTTP 422 Unprocessable Entityになり、認証できない。

 

原因: フロントが送信するJSONとFastAPI側エンドポイントの受け取り方が一致していませんでした。具体的にはFastAPI側が関数引数email: str, password: strで定義していたのに対し、フロントはJSONオブジェクト {"email": "...", "password": "..."} を送信していたため、FastAPIはリクエストボディを解釈できず422エラーを返していました。

 

解決: FastAPI側のエンドポイントを修正し、Pydanticのモデル（例: LoginRequest）でリクエストボディ全体を受け取るように変更しました。修正前後のコードは次の通りです:

# 修正前（誤り）
@app.post("/auth/login")
async def login_user(email: str, password: str, db: Session = Depends(get_db)):
    ...

# 修正後（正しくPydanticモデルを使用）
class LoginRequest(BaseModel):
    email: str
    password: str

@app.post("/auth/login")
async def login_user(credentials: LoginRequest, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.email == credentials.email).first()
    if not user or not verify_password(credentials.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid credentials")
    ...


修正後は422エラーが解消され、正常にログイン処理が行えるようになりました。

 

教訓: フロントエンドとバックエンドのデータ形式の整合が重要であると改めて認識しました。Pydanticモデルを活用することで、受け取りデータのバリデーションも自動化でき、型のずれによる不具合を防ぎやすくなります。また、問題発生時には基本的な部分（FastAPI単体での挙動、CORS設定、Pydanticの単純なバリデーションなど）を段階的にテストし、原因を切り分けていくことが有効でした。

ケース2: Amplifyでデプロイしたフロントエンドが404エラーになる

発生状況: Amplify HostingでNext.jsアプリをデプロイ。ビルドは成功しているが、いざURLにアクセスすると「404 Not Found」でアプリが表示されない。

 

原因: Amplifyのモノレポ対応設定が不十分でした。今回リポジトリはfrontend/にNext.jsコード、backend/にFastAPIコードが入る構成で、Amplifyはこれをモノレポとみなします。しかし、初期設定のamplify.ymlにはapplicationsキーがなく、Amplify側が正しくフロントエンドのルートを認識できていませんでした。さらにAmplifyコンソールで AMPLIFY_MONOREPO_APP_ROOT 環境変数が自動設定されていたため、YAMLとの不整合が生じていました。

 

解決: amplify.ymlをモノレポ対応の形式に書き換え、環境変数も整合を取ることで解決しました（前述「Amplifyデプロイ設定」で示したYAML参照）。具体的には applications: キーの下に appRoot: frontend を指定し、その下でビルド/出力ディレクトリ等を設定しました。またAmplify側環境変数には AMPLIFY_MONOREPO_APP_ROOT=frontend を設定し、不要な設定は整理しました。

 

修正後に再デプロイしたところ、404エラーは解消し、アプリに正常にアクセスできるようになりました。

 

教訓: Amplifyでモノレポを扱う場合、ドキュメントに記載の設定を正しく反映する必要があります。特にapplicationsキーの導入やappRootの指定など、YAML設定とAmplifyコンソール上の環境変数双方で矛盾がないようにすることが重要です。Node.jsのバージョンもAmplifyデフォルトでは最新LTSになりますが、プロジェクトに合わせ固定しておく（今回Next.js 15に対しNode 20を使用）ことでビルド環境の再現性が高まりトラブルを減らせました。

ケース3: ECSデプロイがCircuit Breakerで失敗する

発生状況: ECSのサービスを作成しデプロイを行ったところ、タスクが起動直後に停止し、ECSサービスでDeployment Circuit Breaker（デプロイのサーキットブレーカー）がトリガーされ失敗となった。CloudWatch Logsやタスクのログを確認するとエラーが発生していた。

 

原因: Dockerイメージにいくつか問題がありました。一つはPython依存ライブラリの不足、もう一つはポート設定ミスです。ログには以下のようなエラーが出ていました:

ModuleNotFoundError: No module named 'sqlalchemy'
ImportError: email-validator is not installed, run `pip install pydantic[email]`


つまりrequirements.txtにSQLAlchemyやemail-validator等、コードで使用しているパッケージが抜けていたためコンテナ起動時にImportErrorで落ちていました。さらにDockerfileのCMDで--port 8080を指定していたため、コンテナ内部で8080番ポートでリッスンしてしまい、ALBからの8080ヘルスチェックに応答できずヘルスチェックで異常と判断されていました。

 

解決: まずrequirements.txtを修正し、漏れていた依存関係をすべて追加しました（前述の依存一覧参照）。特にpydantic[email]のようにエラーメッセージで追加インストールを指示されたものも含めました。次にDockerfileのEXPOSEとCMDを8080に統一しました。

 

これらを修正して再度ビルド→ECRプッシュ→ECSサービスのデプロイ更新を行ったところ（CodeBuild経由なら再ビルド実行、その後ECSサービスをForce new deployment）、タスクが正常に起動し、サービスも安定稼働するようになりました。

 

教訓: 依存関係の管理と設定値の一貫性が重要だと再認識しました。ローカルで動いていたからといって安心せず、コンテナ環境で必要なライブラリがすべてインストールされているか、要求ポートが統一されているかをチェックする必要があります。ECSではログとイベントの確認がトラブルシュートの鍵になります。CloudWatch Logsやdescribe-tasksで詳細を追い、原因を一つずつ潰していく段階的デバッグが有効でした。

ケース4: JWTトークンの検証エラーで認証が通らない

発生状況: ログイン自体は成功するが、FastAPI側のJWT保護エンドポイント（/meなど）が常に401エラーを返してしまう。

 

原因: フロントとバックのJWT設定不整合、またはトークンの取扱い不備が考えられます。例えば、NextAuthのシークレット不一致やAuthorizationヘッダの渡し漏れです。

NextAuthのNEXTAUTH_SECRETがFastAPIのNEXTAUTH_SECRET環境変数と一致していないと、署名検証は必ず失敗します。

フロントエンド側でAPIを呼ぶ際に、fetchのオプションでcredentials: 'include'を指定していないと、クッキー経由のJWTが送信されずFastAPIは認証情報を受け取れません。

解決: .env.localと.envで同じNEXTAUTH_SECRETを設定し直し（開発・本番環境すべてで統一する）、FastAPIを再起動しました。さらにフロントのAPI呼び出しを再点検し、先のコード例のようにcredentials: 'include'を付与してクッキーが送信されるよう修正しました。

 

また、NextAuthのJWTにはデフォルトでexp（有効期限）が短めに設定されています。開発中にトークン有効期限が切れていたケースもありました。NextAuth側の設定でJWTの有効期間(maxAge)を延長したり、開発用に一時的にttlを長くする設定を加えてトラブルの切り分けを行いました。

 

これらの対応で、FastAPI側でも正しく認証済みのリクエストを受け取れるようになりました。

 

教訓: JWTを用いたフロント・バック間の認証では、共有シークレットと設定の同期が最も重要です。僅かな不一致で動かなくなるため、環境変数の管理ミスには十分注意しましょう。また、ブラウザからクッキーを送る場合はCORSのallow_credentials=Trueやcredentials: 'include'の指定が必要になるなど、クライアント側・サーバ側双方の実装を漏れなく整える必要があります。

運用Tips・発展事項 (Tips and Advanced Topics)

最後に、本プロジェクトを運用・発展させていく上でのヒントやベストプラクティスをいくつか紹介します。

Blue/Greenデプロイの活用: ECSサービスのデプロイ方式にBlue/Greenを採用すると、デプロイ失敗時の自動ロールバックやデプロイ中も現行版がユーザーに提供され続けるといった利点があります。AWS CodeDeployを使用してECSのBlue/Greenを構成するには、2つのターゲットグループ（Blue用・Green用）を作成し、CodeDeployのアプリケーションとデプロイグループを設定します。Blue/GreenではECSサービスの定義で1つのターゲットグループ（prod側）だけ紐付け、切り替えはCodeDeployが行います。一連のセットアップは高度ですが、本番環境でのゼロダウンタイムデプロイや安全性向上に寄与します。

CI/CDパイプラインの構築: AmplifyのフロントエンドはGitプッシュ連動で自動デプロイできますが、バックエンドもCodeBuildやGitHub Actionsを使って自動ビルド・デプロイを構築すると便利です。例えばAWS CodeBuildプロジェクトを設定し、GitHubのpushトリガーでDockerイメージをビルドしてECRにプッシュするようにします。さらにCodeDeploy（Blue/Green）と連携すれば、push一つで本番環境へ新バージョンをデプロイ可能です。これにより手動操作を減らしデプロイミスを防げます。

シークレット管理: AWS運用時はデータベースURLやAPIキー、JWTシークレットなど機密情報はAWS Secrets ManagerやSSMパラメータストアに安全に保管し、タスク定義で参照するようにしましょう。環境変数に直書きするとSecretが平文で残ってしまうため、secretsとして注入するのがベストプラクティスです。

モニタリングとログ: CloudWatchを活用してシステムの可観測性を高めましょう。具体例として:

ALBのアクセスログをS3に有効化し、後で分析できるようにする。

CloudWatch Alarmsを設定し、例えばALBの5xxエラー数やECSタスクのCPU使用率が一定以上になったら通知を受け取る。

（必要に応じて）WAF（Web Application Firewall）をALBにアタッチし、SQLインジェクションや不要なBOTアクセスをブロックするルールを適用する。

RDSへの移行とpgvector: 開発でSQLiteを使っていた部分は、本番ではPostgreSQLなどのRDBMSに移行するのが望ましいです。AWSではRDSを利用し、PostgreSQL + pgvector拡張を有効化することでベクトル検索をDB上で行うこともできます。SQLAlchemyでPostgreSQLに接続する場合はDATABASE_URLを変更し、pgvector用のモデル定義（ベクトルカラム型）を追加するなどの対応をします。ChromaDBのようなローカルVectorStoreは不要となり、LangChainからPostgres(pgvector)を使うことも可能です。移行の際はデータの初期投入や、pgvectorの精度チューニングも検討してください。

スケーリング: 負荷に応じてECSのタスク数を増減させるオートスケーリングを設定できます。Application Auto ScalingでCPU使用率などをターゲットにスケーリングポリシーを設定しておくと、急なアクセス増にも対応しやすくなります。またAmplifyのホスティングはCDNが有効で高速ですが、さらにCloudFrontを使って独自のキャッシュ設定やWAFを組み合わせることもできます。

開発プロセスの改善: 今回のようなフルスタック開発では、フロントとバックのインターフェース（API定義やデータ型）を綿密にすり合わせることが重要です。OpenAPIやSwaggerでAPI仕様を共有したり、TypeScriptの型をOpenAPIから生成して共有する方法などもあります。さらに、ユニットテスト・統合テストを充実させ、CIで自動実行することでリファクタリング時の不具合を早期検出できます。