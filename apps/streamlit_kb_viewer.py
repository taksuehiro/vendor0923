import streamlit as st
import pandas as pd
from pathlib import Path
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from rag_core.vectorstore import load_vectorstore
from rag_core.llm import get_embeddings
from rag_core.indexer import resolve_openai_key

def safe_secret(name: str, default: str = "") -> str:
    """secrets.toml ãŒç„¡ã„å ´åˆã§ã‚‚ä¾‹å¤–ã«ã—ãªã„å®‰å…¨ã‚¢ã‚¯ã‚»ã‚µ"""
    try:
        return st.secrets.get(name, default)
    except Exception:
        return default

def resolve_openai_key() -> str:
    # å„ªå…ˆé †: session_state > env > secrets(ã‚ã‚Œã°)
    key = (
        st.session_state.get("OPENAI_API_KEY")
        or os.getenv("OPENAI_API_KEY")
        or safe_secret("OPENAI_API_KEY", "")
    )
    return (key or "").strip().strip('"').strip("'")

def main():
    st.set_page_config(page_title="KBãƒ“ãƒ¥ãƒ¼ã‚¢", page_icon="ðŸ“š", layout="wide")
    st.title("ðŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ“ãƒ¥ãƒ¼ã‚¢")
    
    # è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        st.info("Amazon Bedrock Titan ã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆAPI Keyä¸è¦ï¼‰")
        
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        vector_dir = st.text_input(
            "ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
            value=str(project_root / "vectorstore"),
            help="FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä¿å­˜å…ˆ"
        )
    
    # Bedrock ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨ï¼ˆAPI Keyä¸è¦ï¼‰
    st.caption("Amazon Bedrock Titan ã‚’ä½¿ç”¨ä¸­...")
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®èª­ã¿è¾¼ã¿
    try:
        embeddings = get_embeddings()
        vectorstore, used_dir = load_vectorstore(vector_dir, embeddings)
        
        if vectorstore is None:
            st.error(f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {vector_dir}")
            st.info("å…ˆã«ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            st.stop()
            
    except Exception as e:
        st.error(f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å–å¾—
    try:
        # å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ï¼ˆé¡žä¼¼åº¦æ¤œç´¢ã§ç©ºæ–‡å­—åˆ—ã‚’æŒ‡å®šï¼‰
        all_docs = vectorstore.similarity_search("", k=vectorstore.index.ntotal)
        
        if not all_docs:
            st.warning("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()
            
    except Exception as e:
        st.error(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
    
    # ã‚µãƒžãƒªæƒ…å ±ã®è¨ˆç®—
    total_vendors = len(all_docs)
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°
    status_counts = {}
    category_counts = {}
    source_format_counts = {}
    missing_vendor_id = 0
    
    for doc in all_docs:
        meta = doc.metadata
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥é›†è¨ˆ
        status = meta.get("status", "ä¸æ˜Ž")
        status_counts[status] = status_counts.get(status, 0) + 1
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        category = meta.get("category", "ä¸æ˜Ž")
        category_counts[category] = category_counts.get(category, 0) + 1
        
        # ã‚½ãƒ¼ã‚¹å½¢å¼åˆ¥é›†è¨ˆ
        source_format = meta.get("source_format", "ä¸æ˜Ž")
        source_format_counts[source_format] = source_format_counts.get(source_format, 0) + 1
        
        # vendor_idæ¬ è½ãƒã‚§ãƒƒã‚¯
        if not meta.get("vendor_id"):
            missing_vendor_id += 1
    
    # ã‚µãƒžãƒªè¡¨ç¤º
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·ãƒ™ãƒ³ãƒ€ãƒ¼æ•°", total_vendors)
    
    with col2:
        st.metric("vendor_idæ¬ è½", missing_vendor_id)
    
    with col3:
        st.metric("JSONå½¢å¼", source_format_counts.get("json", 0))
    
    with col4:
        st.metric("Markdownå½¢å¼", source_format_counts.get("md", 0))
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°
    st.subheader("ðŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°")
    status_df = pd.DataFrame(list(status_counts.items()), columns=["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ä»¶æ•°"])
    status_df = status_df.sort_values("ä»¶æ•°", ascending=False)
    st.dataframe(status_df, use_container_width=True)
    
    # ã‚«ãƒ†ã‚´ãƒªä¸Šä½
    st.subheader("ðŸ“Š ã‚«ãƒ†ã‚´ãƒªä¸Šä½")
    category_df = pd.DataFrame(list(category_counts.items()), columns=["ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"])
    category_df = category_df.sort_values("ä»¶æ•°", ascending=False)
    st.dataframe(category_df, use_container_width=True)
    
    # ãƒ•ã‚£ãƒ«ã‚¿
    st.subheader("ðŸ” ãƒ•ã‚£ãƒ«ã‚¿")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        selected_status = st.multiselect(
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
            options=list(status_counts.keys()),
            default=list(status_counts.keys())
        )
    
    with col2:
        selected_category = st.multiselect(
            "ã‚«ãƒ†ã‚´ãƒª",
            options=list(category_counts.keys()),
            default=list(category_counts.keys())
        )
    
    with col3:
        selected_source_format = st.multiselect(
            "ã‚½ãƒ¼ã‚¹å½¢å¼",
            options=list(source_format_counts.keys()),
            default=list(source_format_counts.keys())
        )
    
    # ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
    filtered_docs = []
    for doc in all_docs:
        meta = doc.metadata
        if (meta.get("status", "ä¸æ˜Ž") in selected_status and
            meta.get("category", "ä¸æ˜Ž") in selected_category and
            meta.get("source_format", "ä¸æ˜Ž") in selected_source_format):
            filtered_docs.append(doc)
    
    st.info(f"ãƒ•ã‚£ãƒ«ã‚¿çµæžœ: {len(filtered_docs)}ä»¶ / {total_vendors}ä»¶")
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§
    st.subheader("ðŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§")
    
    for i, doc in enumerate(filtered_docs):
        meta = doc.metadata
        
        with st.expander(f"{i+1}. {meta.get('name', 'Unknown')} ({meta.get('vendor_id', 'No ID')})", expanded=False):
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.markdown("**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:**")
                st.json(meta)
            
            with col2:
                st.markdown("**å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:**")
                content = doc.page_content
                st.text(content[:500] + ("..." if len(content) > 500 else ""))
                
                # vendor_idã‚¯ãƒªãƒƒã‚¯å¯èƒ½
                vendor_id = meta.get("vendor_id")
                if vendor_id:
                    if st.button(f"ðŸ” {vendor_id} ã§æ¤œç´¢", key=f"search_{i}"):
                        st.session_state[f"search_query_{i}"] = vendor_id
                
                # æ¤œç´¢çµæžœè¡¨ç¤º
                if f"search_query_{i}" in st.session_state:
                    query = st.session_state[f"search_query_{i}"]
                    try:
                        search_results = vectorstore.similarity_search(query, k=3)
                        st.markdown(f"**ã€Œ{query}ã€ã®æ¤œç´¢çµæžœ:**")
                        for j, result in enumerate(search_results):
                            with st.expander(f"çµæžœ {j+1}", expanded=False):
                                st.text(result.page_content[:300] + ("..." if len(result.page_content) > 300 else ""))
                    except Exception as e:
                        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()


