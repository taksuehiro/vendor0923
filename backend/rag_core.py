# backend/rag_core.py
from __future__ import annotations
import os
import json
from pathlib import Path
from typing import List, Dict, Any

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_core.documents import Document

# ç’°å¢ƒå¤‰æ•°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
VECTOR_DIR = Path(os.getenv("VECTOR_DIR", "/app/vectorstore")).resolve()
DATA_PATH = Path(os.getenv("VENDOR_DATA_JSON", "/app/data/vendors.json")).resolve()

INDEX_NAME = "vendors"

class VendorRAG:
    def __init__(self) -> None:
        if not OPENAI_API_KEY:
            raise RuntimeError("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ .env.local / .env ã‚’ã€ECS ã§ã¯ Secrets Manager çµŒç”±ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")

        self.embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        self.vs: FAISS | None = None

    # æ°¸ç¶šãƒ‘ã‚¹
    def _index_dir(self) -> Path:
        return VECTOR_DIR / INDEX_NAME

    def _exists(self) -> bool:
        p = self._index_dir()
        return (p / "index.faiss").exists() and (p / "index.pkl").exists()

    def load_or_build(self) -> None:
        VECTOR_DIR.mkdir(parents=True, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°ãƒã‚§ãƒƒã‚¯
        should_rebuild = False
        if self._exists():
            # æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°æ—¥æ™‚ã¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã‚’æ¯”è¼ƒ
            index_time = max(
                (self._index_dir() / "index.faiss").stat().st_mtime,
                (self._index_dir() / "index.pkl").stat().st_mtime
            )
            if DATA_PATH.exists():
                data_time = DATA_PATH.stat().st_mtime
                if data_time > index_time:
                    should_rebuild = True
                    print(f"ðŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸã€‚ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’å†æ§‹ç¯‰ã—ã¾ã™...")
            else:
                should_rebuild = True
        else:
            should_rebuild = True
            print(f"ðŸ“Š ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦æ§‹ç¯‰ã—ã¾ã™...")

        if not should_rebuild:
            print(f"ðŸ“Š æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {self._index_dir()}")
            self.vs = FAISS.load_local(
                str(self._index_dir()),
                self.embeddings,
                allow_dangerous_deserialization=True,
            )
            return

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæœ€ä½Žé™ã®ã‚¹ã‚­ãƒ¼ãƒž: id, name, description, status, categoryï¼‰
        docs: List[Document] = []
        if DATA_PATH.exists():
            print(f"ðŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {DATA_PATH}")
            items = json.loads(DATA_PATH.read_text(encoding="utf-8"))
            print(f"ðŸ“Š {len(items)}ä»¶ã®ãƒ™ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        else:
            print(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {DATA_PATH}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®ã‚µãƒ³ãƒ—ãƒ«
            items = [
                {"id": "V-LiberCraft", "name": "LiberCraft", "description": "AIãƒ»æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸã‚¹ã‚¯ãƒ©ãƒƒãƒé–‹ç™ºã‚µãƒ¼ãƒ“ã‚¹ã€‚å¥‘ç´„æ›¸ç®¡ç†ã‚„æ³•å‹™æ¥­å‹™ã®è‡ªå‹•åŒ–ã«å¼·ã¿ã€‚", "status": "é¢è«‡æ¸ˆ", "category": "ã‚¹ã‚¯ãƒ©ãƒƒãƒ"},
                {"id": "V-TechCorp", "name": "TechCorp", "description": "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©æ§‹ç¯‰ãƒ»é‹ç”¨æ”¯æ´ã®SaaSã€‚å¥‘ç´„ç®¡ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é€£æºã«å®Ÿç¸¾ã€‚", "status": "æœªé¢è«‡", "category": "SaaS"},
            ]
            print(f"ðŸ“Š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ {len(items)}ä»¶ã‚’ä½¿ç”¨ã—ã¾ã™")

        for it in items:
            # ã‚ˆã‚Šè©³ç´°ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            name = it.get('name', '')
            description = it.get('description', '')
            status = it.get('status', '')
            category = it.get('category', '')
            
            # æ¤œç´¢ã«é©ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
            text_parts = [name]
            if description:
                text_parts.append(description)
            if status:
                text_parts.append(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
            if category:
                text_parts.append(f"ã‚«ãƒ†ã‚´ãƒª: {category}")
            
            text = "ã€‚".join(text_parts)
            meta = {k: v for k, v in it.items() if k not in ("description",)}
            docs.append(Document(page_content=text, metadata=meta))

        print(f"ðŸ“Š ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰ä¸­...")
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ
        self.vs = FAISS.from_documents(docs, self.embeddings, docstore=InMemoryDocstore())
        self.vs.save_local(str(self._index_dir()))
        print(f"ðŸ“Š ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {self._index_dir()}")

    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        if self.vs is None:
            self.load_or_build()
        assert self.vs is not None

        hits = self.vs.similarity_search_with_score(query, k=top_k)
        results = []
        for doc, score in hits:
            meta = dict(doc.metadata)
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿è¨¼
            status = meta.get("status", "")
            category = meta.get("category", "")
            
            results.append({
                "id": meta.get("id") or meta.get("vendor_id") or meta.get("name"),
                "title": meta.get("name"),
                "score": float(score),
                "snippet": doc.page_content[:240],
                "metadata": {
                    "status": status,
                    "category": category
                },
            })
        return results

# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³åˆ©ç”¨
_rag: VendorRAG | None = None

def get_rag() -> VendorRAG:
    global _rag
    if _rag is None:
        _rag = VendorRAG()
        _rag.load_or_build()
    return _rag

def search_vendors(query: str, top_k: int = 5):
    return get_rag().search(query, top_k)
