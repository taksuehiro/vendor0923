from pathlib import Path
from dotenv import load_dotenv
import os
import streamlit as st
import pandas as pd
from collections import Counter, defaultdict

ROOT = Path(__file__).parent
load_dotenv(dotenv_path=ROOT / ".env", override=False)

def safe_secret(name: str, default: str = "") -> str:
    """secrets.toml ãŒç„¡ã„å ´åˆã§ã‚‚ä¾‹å¤–ã«ã—ãªã„å®‰å…¨ã‚¢ã‚¯ã‚»ã‚µ"""
    try:
        return st.secrets.get(name, default)  # type: ignore[attr-defined]
    except Exception:
        return default

def resolve_openai_key() -> str:
    # å„ªå…ˆé †: session_state > env > secrets(ã‚ã‚Œã°)
    key = (
        st.session_state.get("OPENAI_API_KEY")
        or os.getenv("OPENAI_API_KEY")
        or safe_secret("OPENAI_API_KEY", "")
    )
    return (key or "").strip().strip('"').strip("'")

import shutil

import config
from rag_core.loader import load_md
from rag_core.splitter import make_splits
from rag_core.vectorstore import build_or_load_vectorstore
from rag_core.llm import get_embeddings, get_chat
from rag_core.chain import load_prompt, make_chain
from rag_core.indexer import find_best_data_file, load_documents_auto, load_documents_from_dir, build_faiss

def read_prompt_file(path: Path) -> str:
    if not path.exists():
        return "ã€æ–‡è„ˆã€‘\n{context}\n\nã€è³ªå•ã€‘\n{question}\n\nã€å›žç­”ã€‘"
    return path.read_text(encoding="utf-8")

def _to_safe_list(x):
    """å€¤ã‚’å®‰å…¨ãªãƒªã‚¹ãƒˆã«å¤‰æ›"""
    if isinstance(x, list): 
        return x
    if x is None: 
        return []
    return [x]

def build_kb_index(docs):
    """docs ã‹ã‚‰é›†è¨ˆã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œã‚‹"""
    by_id = {}
    facets = {
        "status": Counter(),
        "listed": Counter(),
        "type": Counter(),
        "use_cases": Counter(),
    }
    # é›†è¨ˆã¨åŸºç¤Žè¾žæ›¸
    for d in docs:
        m = d.metadata or {}
        vid = m.get("vendor_id") or m.get("name")
        if not vid: 
            continue
        by_id[vid] = {
            "vendor_id": vid,
            "name": m.get("name"),
            "status": m.get("status") or "ä¸æ˜Ž",
            "listed": m.get("listed") or "ä¸æ˜Ž",
            "type": m.get("type") or "ãã®ä»–",
            "use_cases": _to_safe_list(m.get("use_cases")),
            "url": m.get("url"),
            "employees_band": m.get("employees_band"),
            "investors": _to_safe_list(m.get("investors")),
            "is_scratch": m.get("is_scratch"),
            "category": m.get("category"),
            "deployment": m.get("deployment"),
            "price_range": m.get("price_range"),
            # è©³ç´°è¡¨ç¤ºç”¨
            "industries": _to_safe_list(m.get("industries")),
            "departments": _to_safe_list(m.get("departments")),
            "doc": d,
        }
        facets["status"][by_id[vid]["status"]] += 1
        facets["listed"][by_id[vid]["listed"]] += 1
        facets["type"][by_id[vid]["type"]] += 1
        for u in by_id[vid]["use_cases"]:
            facets["use_cases"][u] += 1
    return by_id, facets

def render_summary_cards(facets):
    """ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªé›†è¨ˆã‚«ãƒ¼ãƒ‰ç¾¤ã€‚ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‚‰ state ã«ä¿å­˜"""
    st.subheader("é›†è¨ˆï¼ˆã‚¯ãƒªãƒƒã‚¯ã§ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼‰")
    c1, c2, c3 = st.columns(3)

    # é¢è«‡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    with c1:
        st.caption("é¢è«‡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
        cols = st.columns(max(1, len(facets["status"])))
        for i, (k, v) in enumerate(facets["status"].most_common()):
            if cols[i].button(f"{k}ï¼š{v}ç¤¾", key=f"btn_status_{k}"):
                st.session_state["browse_clicked"] = ("status", k)

    # ä¸Šå ´åŒºåˆ†
    with c2:
        st.caption("ä¸Šå ´åŒºåˆ†")
        cols = st.columns(max(1, len(facets["listed"])))
        for i, (k, v) in enumerate(facets["listed"].most_common()):
            if cols[i].button(f"{k}ï¼š{v}ç¤¾", key=f"btn_listed_{k}"):
                st.session_state["browse_clicked"] = ("listed", k)

    # ã‚¿ã‚¤ãƒ—
    with c3:
        st.caption("ã‚¿ã‚¤ãƒ—")
        cols = st.columns(max(1, len(facets["type"])))
        for i, (k, v) in enumerate(facets["type"].most_common()):
            if cols[i].button(f"{k}ï¼š{v}ç¤¾", key=f"btn_type_{k}"):
                st.session_state["browse_clicked"] = ("type", k)

def render_vendor_list(by_id, filters, clicked=None):
    """ãƒ•ã‚£ãƒ«ã‚¿ã¨ã‚¯ãƒªãƒƒã‚¯æ¡ä»¶ã‹ã‚‰ä¸€è¦§ã‚’å‡ºã™"""
    def match(v):
        # status
        if filters["status"] and v["status"] not in filters["status"]:
            return False
        # listed
        if filters["listed"] and v["listed"] not in filters["listed"]:
            return False
        # type
        if filters["type"] and v["type"] not in filters["type"]:
            return False
        # use_cases (ANDã§ã¯ãªãORãƒžãƒƒãƒ)
        if filters["use_cases"]:
            if not set(v["use_cases"]).intersection(filters["use_cases"]):
                return False
        # ã‚«ãƒ¼ãƒ‰ã‚¯ãƒªãƒƒã‚¯ã®çµžã‚Š
        if clicked:
            key, val = clicked
            if key == "use_cases":
                return val in v["use_cases"]
            return v.get(key) == val
        return True

    rows = [v for v in by_id.values() if match(v)]
    rows = sorted(rows, key=lambda x: (x["status"] != "é¢è«‡æ¸ˆ", x["name"] or ""))  # é¢è«‡æ¸ˆã‚’ä¸Šã«

    st.markdown(f"**è©²å½“ï¼š{len(rows)}ç¤¾**")
    for v in rows:
        with st.expander(f"{v['name']} ã€”{v['status']} / {v['listed']} / {v['type']}ã€•", expanded=False):
            st.markdown(f"- **Vendor ID**: `{v['vendor_id']}`")
            st.markdown(f"- **URL**: {v['url'] or '-'}")
            st.markdown(f"- **å¾—æ„åˆ†é‡Ž**: {', '.join(v['use_cases']) or '-'}")
            st.markdown(f"- **æ¥­ç•Œ**: {', '.join(v['industries']) or '-'}")
            st.markdown(f"- **éƒ¨é–€**: {', '.join(v['departments']) or '-'}")
            st.markdown(f"- **ãƒ‡ãƒ—ãƒ­ã‚¤**: {v['deployment'] or '-'}  / **ä¾¡æ ¼å¸¯**: {v['price_range'] or '-'}")
            st.markdown(f"- **å¾“æ¥­å“¡è¦æ¨¡**: {v['employees_band'] or '-'}  / **æŠ•è³‡å®¶**: {', '.join(v['investors']) or '-'}")
            # å³ï¼ˆä¸‹ï¼‰å´ã§æœ¬æ–‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.code(v["doc"].page_content[:1200], language="markdown")

def browse_tab(docs):
    """ãƒ–ãƒ©ã‚¦ã‚ºã‚¿ãƒ–ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if not docs:
        st.warning("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return
    by_id, facets = build_kb_index(docs)

    # ãƒ•ã‚£ãƒ«ã‚¿ UI
    with st.sidebar:
        st.subheader("ãƒ–ãƒ©ã‚¦ã‚ºï¼šãƒ•ã‚£ãƒ«ã‚¿")
        f_status = st.multiselect("é¢è«‡ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", options=list(facets["status"].keys()), default=[])
        f_listed = st.multiselect("ä¸Šå ´åŒºåˆ†", options=list(facets["listed"].keys()), default=[])
        f_type = st.multiselect("ã‚¿ã‚¤ãƒ—", options=list(facets["type"].keys()), default=[])
        f_use = st.multiselect("å¾—æ„åˆ†é‡Žï¼ˆuse_casesï¼‰", options=list(facets["use_cases"].keys()), default=[])
        if st.button("ãƒ•ã‚£ãƒ«ã‚¿ã‚’ã‚¯ãƒªã‚¢"):
            f_status, f_listed, f_type, f_use = [], [], [], []
            st.session_state.pop("browse_clicked", None)

    # é›†è¨ˆã‚«ãƒ¼ãƒ‰ï¼ˆã‚¯ãƒªãƒƒã‚¯å¯¾å¿œï¼‰
    render_summary_cards(facets)

    clicked = st.session_state.get("browse_clicked")  # ä¾‹: ("status","æœªé¢è«‡")
    if clicked:
        key, val = clicked
        st.info(f"ãƒ‰ãƒªãƒ«ãƒ€ã‚¦ãƒ³ï¼š{key} = {val}")

    # ä¸€è¦§
    render_vendor_list(
        by_id,
        filters={"status": f_status, "listed": f_listed, "type": f_type, "use_cases": f_use},
        clicked=clicked
    )

def main():
    st.set_page_config(page_title="ãƒ™ãƒ³ãƒ€ãƒ¼æ¤œç´¢ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«RAGï¼‰", page_icon="ðŸ”Ž", layout="wide")
    st.title("ðŸ”Ž ãƒ™ãƒ³ãƒ€ãƒ¼æ¤œç´¢ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«RAG, Streamlitï¼‰")
    st.caption("KEY head: " + (resolve_openai_key()[:10] if resolve_openai_key() else ""))

    # Sidebar - èª¿æ•´UI
    with st.sidebar:
        st.header("âš™ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")

        current_key = resolve_openai_key()
        api_key_input = st.text_input("OpenAI API Keyï¼ˆå¿…è¦ãªã‚‰å…¥åŠ›ï¼‰", type="password", value=current_key)
        if api_key_input and api_key_input != current_key:
            st.session_state["OPENAI_API_KEY"] = api_key_input
            os.environ["OPENAI_API_KEY"] = api_key_input
            st.success("APIã‚­ãƒ¼ã‚’åæ˜ ã—ã¾ã—ãŸ")

        st.divider()
        st.subheader("ðŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•é¸æŠžï¼ˆvendors.jsonå„ªå…ˆï¼‰
        data_dir = ROOT / "data"
        
        def resolve_default_path() -> Path:
            """vendors.json â†’ æ—§å â†’ ä»–ã® .json â†’ .md ã®å„ªå…ˆé †ã§é¸æŠž"""
            candidates = [
                data_dir / "vendors.json",
                data_dir / "ãƒ™ãƒ³ãƒ€ãƒ¼èª¿æŸ»JSONç·´ç¿’ç‰ˆ.json",
                data_dir / "ãƒ™ãƒ³ãƒ€ãƒ¼èª¿æŸ».json",
            ]
            for c in candidates:
                if c.exists():
                    return c
            j = sorted(data_dir.glob("*.json"))
            if j:
                return j[0]
            m = sorted(list(data_dir.glob("*.md")) + list(data_dir.glob("*.markdown")))
            if m:
                return m[0]
            return data_dir
        
        try:
            auto_file = resolve_default_path()
            default_input = str(auto_file)
            st.caption(f"è‡ªå‹•é¸æŠž: {auto_file.name}")
        except Exception:
            default_input = str(data_dir / "vendors.json")
            st.caption("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        input_path = st.text_input("å…¥åŠ›ãƒ‘ã‚¹ï¼ˆ.json/.md ã¾ãŸã¯ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰", value=default_input)
        
        # JSONã®å ´åˆã¯chunk_size=0å›ºå®š
        is_json = input_path.lower().endswith('.json')
        if is_json:
            st.caption("JSONå½¢å¼: chunk_size=0å›ºå®šï¼ˆ1ãƒ™ãƒ³ãƒ€ãƒ¼=1ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")
            effective_chunk_size = 0
        else:
            effective_chunk_size = chunk_size
        
        load_data = st.button("ðŸ“¥ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ / å†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹", use_container_width=True)

        top_k = st.slider("Top Kï¼ˆå–å¾—æ–‡æ›¸æ•°ï¼‰", 1, 15, config.DEFAULT_TOP_K)
        chunk_size = st.number_input(
            "ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º",
            min_value=0,
            max_value=2000,
            value=config.CHUNK_SIZE,
            step=50,
            help="0 ã‚’æŒ‡å®šã™ã‚‹ã¨æ–‡å­—æ•°ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ™ãƒ³ãƒ€ãƒ¼å˜ä½ã®ã¿ï¼‰"
        )
        chunk_overlap = st.number_input(
            "ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—",
            min_value=0,
            max_value=500,
            value=config.CHUNK_OVERLAP,
            step=20,
            help="æ–‡å­—æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ä½¿ã†å ´åˆã®ã¿æœ‰åŠ¹ï¼ˆchunk_size>0ï¼‰ã€‚"
        )
        use_mmr = st.checkbox("MMRã‚’ä½¿ã†ï¼ˆå¤šæ§˜æ€§ï¼‰", value=config.USE_MMR)
        st.caption("â€» MMRã¯é¡žä¼¼ã—ã™ãŽã‚‹å€™è£œã‚’æ¸›ã‚‰ã—ã¦å¤šæ§˜åŒ–ã—ã¾ã™")
        score_threshold = st.number_input("ã‚¹ã‚³ã‚¢ã—ãã„å€¤ï¼ˆ0.0ï½ž1.0 / ç©ºæ¬„ã§æœªä½¿ç”¨ï¼‰", min_value=0.0, max_value=1.0, value=0.0, step=0.05)
        threshold = None if score_threshold == 0.0 else score_threshold

        st.divider()
        embed_model = st.selectbox("Embeddings", ["text-embedding-3-small", "text-embedding-3-large"], index=0)
        chat_model = st.selectbox("Chat Model", ["gpt-3.5-turbo", "gpt-4o-mini"], index=0)
        temperature = st.slider("Temperature", 0.0, 1.0, config.TEMPERATURE, 0.1)

        reindex = st.button("ðŸ”„ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†ä½œæˆï¼ˆãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æ¶ˆåŽ»ï¼‰")

        st.divider()
        st.caption("FAISS ä¿å­˜å…ˆï¼ˆASCIIãƒ‘ã‚¹æŽ¨å¥¨ï¼‰")
        vector_dir_input = st.text_input(
            "Vectorstore Directory",
            value=str(config.VECTOR_DIR),
            help="æ—¥æœ¬èªžãªã©éžASCIIã‚’å«ã¾ãªã„ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ï¼ˆä¾‹: C:\\vendor0922\\vectorstoreï¼‰"
        )
        
        # ASCIIãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        def _is_ascii(s: str) -> bool:
            try:
                s.encode("ascii")
                return True
            except UnicodeEncodeError:
                return False

        if vector_dir_input and not _is_ascii(vector_dir_input):
            st.error("ä¿å­˜å…ˆã«æ—¥æœ¬èªžãªã©éžASCIIæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ASCIIã®ã¿ã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é€šéŽå¾Œã«ä½œæˆ
        if vector_dir_input:
            os.makedirs(vector_dir_input, exist_ok=True)
        st.caption(f"Vectorstore Dir (effective): {vector_dir_input}")

    # å†ä½œæˆãªã‚‰vectorstoreå‰Šé™¤
    if reindex and vector_dir_input:
        shutil.rmtree(vector_dir_input, ignore_errors=True)
        os.makedirs(vector_dir_input, exist_ok=True)
        st.toast("æ—¢å­˜ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚æ¬¡å›žæ¤œç´¢æ™‚ã«å†ä½œæˆã—ã¾ã™ã€‚", icon="ðŸ—‘ï¸")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ–°ã—ã„ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    if load_data or "docs" not in st.session_state:
        # èª­ã¿è¾¼ã¿å‰ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
        if load_data:
            for k in ("docs", "vs"):
                if k in st.session_state:
                    del st.session_state[k]
        
        try:
            input_path_obj = Path(input_path)
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ï¼šæŒ‡å®šãƒ‘ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            if not input_path_obj.exists():
                fallback = resolve_default_path()
                st.info(f"æŒ‡å®šãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™: {fallback}")
                input_path_obj = fallback
            
            if input_path_obj.is_dir():
                docs = load_documents_from_dir(input_path_obj, chunk_size=effective_chunk_size, chunk_overlap=chunk_overlap)
                st.success(f"ðŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªèª­ã¿è¾¼ã¿å®Œäº†: {input_path_obj}ï¼ˆ{len(docs)} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")
            else:
                docs = load_documents_auto(input_path_obj, chunk_size=effective_chunk_size, chunk_overlap=chunk_overlap)
                st.success(f"ðŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {input_path_obj.name}ï¼ˆ{len(docs)} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")
            
            st.session_state["docs"] = docs
            st.session_state["loaded_file"] = str(input_path_obj)
            
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            st.info("ðŸ’¡ data/ ã« vendors.json ã‹ .md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ã„ã¦ãã ã•ã„")
            st.stop()
    else:
        docs = st.session_state.get("docs", [])
        loaded_file = st.session_state.get("loaded_file", "ä¸æ˜Ž")
        st.caption(f"ðŸ“„ èª­ã¿è¾¼ã¿æ¸ˆã¿: {Path(loaded_file).name}ï¼ˆ{len(docs)} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")

    # Embeddings / LLM æº–å‚™ã®ç›´å‰ã«ã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
    api_key = resolve_openai_key()
    st.caption("KEY head: " + (api_key[:10] if api_key else ""))  # ç¢ºèªè¡¨ç¤º

    if not api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™ã€‚å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ä»¥é™ã€æ˜Žç¤ºçš„ã«ã‚­ãƒ¼ã‚’æ¸¡ã™
    embeddings = get_embeddings(embed_model, api_key=api_key)
    llm = get_chat(chat_model, temperature=temperature, api_key=api_key)

    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç”¨æ„
    try:
        vectorstore, created, used_dir = build_or_load_vectorstore(
            docs=docs,
            embeddings=embeddings,
            persist_dir=vector_dir_input,
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            splitter_fn=make_splits,
        )
        st.info("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢: æ–°è¦ä½œæˆ" if created else "ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢: æ—¢å­˜ã‚’ä½¿ç”¨")
        st.caption(f"å®Ÿéš›ã®ä¿å­˜å…ˆ: {used_dir}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã¨å®Ÿéš›ã®ä¿å­˜å…ˆãŒé•ã† â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ãŸåˆå›³
        if used_dir and vector_dir_input and used_dir.strip().lower() != vector_dir_input.strip().lower():
            st.warning("æŒ‡å®šãƒ‘ã‚¹ã«ä¿å­˜ã§ããªã‹ã£ãŸãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å…ˆã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚")
    except ValueError as e:
        st.error(str(e))
        st.stop()
    

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt_text = read_prompt_file(config.PROMPT_PATH)
    prompt = load_prompt(prompt_text)

    # ã‚¿ãƒ–UI
    tab1, tab2, tab3 = st.tabs(["ðŸ”Ž æ¤œç´¢UI", "ðŸ“š KBãƒ“ãƒ¥ãƒ¼ã‚¢", "ðŸ“Š ãƒ–ãƒ©ã‚¦ã‚º"])
    
    with tab1:
        # å…¥åŠ›UI
        st.subheader("è³ªå•ã‚’å…¥åŠ›")
        q = st.text_input("ä¾‹: æ³•å‹™ã‚«ãƒ†ã‚´ãƒªã§ä¾¡æ ¼å¸¯ãŒä½Žã„ãƒ™ãƒ³ãƒ€ãƒ¼ã‚’æ•™ãˆã¦", key="query")
        go = st.button("æ¤œç´¢", type="primary")

        if go or q:
            with st.spinner("æ¤œç´¢ä¸­..."):
                try:
                    chain = make_chain(
                        vectorstore=vectorstore,
                        llm=llm,
                        top_k=top_k,
                        prompt=prompt,
                        use_mmr=use_mmr,
                        score_threshold=threshold
                    )
                    result = chain({"query": q})

                    st.subheader("ðŸ“ å›žç­”")
                    st.write(result["result"])

                    if result.get("source_documents"):
                        with st.expander("ðŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹æŠœç²‹ï¼ˆä¸Šä½3ä»¶ï¼‰", expanded=False):
                            for i, doc in enumerate(result["source_documents"][:3]):
                                st.markdown(f"**ã‚½ãƒ¼ã‚¹ {i+1}** - `{doc.metadata.get('file_path')}`")
                                txt = doc.page_content
                                st.text(txt[:800] + ("..." if len(txt) > 800 else ""))
                                st.caption(str(doc.metadata))

                except Exception as e:
                    st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    with tab2:
        st.subheader("ðŸ“š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ“ãƒ¥ãƒ¼ã‚¢")
        
        if not docs:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        else:
            # ã‚µãƒžãƒªæƒ…å ±ã®è¨ˆç®—
            from collections import Counter, defaultdict
            
            total_vendors = len(docs)
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°
            status_counts = Counter([d.metadata.get("status", "ä¸æ˜Ž") for d in docs])
            category_counts = Counter([d.metadata.get("category", "ä¸æ˜Ž") for d in docs])
            source_format_counts = Counter([d.metadata.get("source_format", "ä¸æ˜Ž") for d in docs])
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¬ æãƒã‚§ãƒƒã‚¯
            missing = defaultdict(list)
            for i, d in enumerate(docs):
                for key in ("vendor_id", "name", "category", "status"):
                    if not d.metadata.get(key):
                        missing[key].append(i)
            
            # ã‚µãƒžãƒªè¡¨ç¤º
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ç·ãƒ™ãƒ³ãƒ€ãƒ¼æ•°", total_vendors)
            
            with col2:
                st.metric("vendor_idæ¬ è½", len(missing.get("vendor_id", [])))
            
            with col3:
                st.metric("JSONå½¢å¼", source_format_counts.get("json", 0))
            
            with col4:
                st.metric("Markdownå½¢å¼", source_format_counts.get("md", 0))
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°
            st.subheader("ðŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ä»¶æ•°")
            status_df = pd.DataFrame(list(status_counts.items()), columns=["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ä»¶æ•°"])
            status_df = status_df.sort_values("ä»¶æ•°", ascending=False)
            st.dataframe(status_df, use_container_width=True)
            
            # ã‚«ãƒ†ã‚´ãƒªä¸Šä½
            st.subheader("ðŸ“Š ã‚«ãƒ†ã‚´ãƒªä¸Šä½")
            category_df = pd.DataFrame(list(category_counts.items()), columns=["ã‚«ãƒ†ã‚´ãƒª", "ä»¶æ•°"])
            category_df = category_df.sort_values("ä»¶æ•°", ascending=False)
            st.dataframe(category_df, use_container_width=True)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¬ æè¡¨ç¤º
            if missing:
                st.warning("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¬ æ: " + ", ".join([f"{k}={len(v)}ä»¶" for k,v in missing.items()]))
            else:
                st.info("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ¬ æãªã—")
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§
            st.subheader("ðŸ“‹ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§")
            
            for i, doc in enumerate(docs[:50]):  # è¡¨ç¤ºä¸Šé™
                meta = doc.metadata
                
                with st.expander(f"#{i+1} {meta.get('vendor_id', 'No ID')} â€” {meta.get('name', 'Unknown')}", expanded=False):
                    col1, col2 = st.columns([1, 2])
                    
                    with col1:
                        st.markdown("**ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:**")
                        st.json(meta)
                    
                    with col2:
                        st.markdown("**å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:**")
                        content = doc.page_content
                        st.text(content[:500] + ("..." if len(content) > 500 else ""))
                        
                        # vendor_idã‚¯ãƒªãƒƒã‚¯å¯èƒ½
                        vendor_id = meta.get("vendor_id")
                        if vendor_id and vectorstore:
                            if st.button(f"ðŸ” {vendor_id} ã§æ¤œç´¢", key=f"search_{i}"):
                                st.session_state[f"search_query_{i}"] = vendor_id
                        
                        # æ¤œç´¢çµæžœè¡¨ç¤º
                        if f"search_query_{i}" in st.session_state and vectorstore:
                            query = st.session_state[f"search_query_{i}"]
                            try:
                                search_results = vectorstore.similarity_search(query, k=3)
                                st.markdown(f"**ã€Œ{query}ã€ã®æ¤œç´¢çµæžœ:**")
                                for j, result in enumerate(search_results):
                                    with st.expander(f"çµæžœ {j+1}", expanded=False):
                                        st.text(result.page_content[:300] + ("..." if len(result.page_content) > 300 else ""))
                            except Exception as e:
                                st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
    
    with tab3:
        # ãƒ–ãƒ©ã‚¦ã‚ºã‚¿ãƒ–
        docs = st.session_state.get("docs", [])
        browse_tab(docs)

if __name__ == "__main__":
    main()